[
  {
    "objectID": "tutorials/analysis_sbm.html",
    "href": "tutorials/analysis_sbm.html",
    "title": "Analyzing SBM",
    "section": "",
    "text": "In this notebook, we aim at visualizing what the trained SPIVAE learned. We look into the output, the latent neurons, and the loss distribution of the model.",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Analyzing SBM"
    ]
  },
  {
    "objectID": "tutorials/analysis_sbm.html#latent-neuron-activations-distribution",
    "href": "tutorials/analysis_sbm.html#latent-neuron-activations-distribution",
    "title": "Analyzing SBM",
    "section": "Latent neuron activations distribution",
    "text": "Latent neuron activations distribution\nThe following plots show the distribution of the mean and variance activations. Two neurons have a spread mean and very small variances, while the rest of neurons’ activations lie around zero mean and unit variance. Colors indicate each latent neuron index.\n\nfig, axs = plt.subplots(1,2,sharey=True,gridspec_kw=dict(wspace=0));\naxs[0].hist(mu.T, 100, histtype='step', log=True);\naxs[0].set_xlabel(r'$\\mu$ neuron activation');\naxs[0].set_ylabel('Counts');\naxs[1].hist(np.exp(logvar).T, 100, histtype='step', log=True);\naxs[1].set_xlabel(r'$\\sigma^2$ neuron activation');\n\n\n\n\n\n\n\n\nWe can also detect which neurons are being informative with simple metrics. For instance, the authors of Lu et al. Phys. Rev. X 10, 031056 make use of two quantities, the variance of the mean, and the mean of the variance (we use here the logarithm for visual convenience).\n\nplt.plot(mu.var(0), label=r'Var($\\mu$)');\nplt.plot(logvar.mean(0), label=r'Mean($\\log\\sigma^2$)');\nplt.xlabel('Latent neuron'); plt.legend();",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Analyzing SBM"
    ]
  },
  {
    "objectID": "tutorials/analysis_sbm.html#mu-relation-with-alpha-and-d_0",
    "href": "tutorials/analysis_sbm.html#mu-relation-with-alpha-and-d_0",
    "title": "Analyzing SBM",
    "section": "\\(\\mu\\) relation with \\(\\alpha\\) and \\(D_0\\)",
    "text": "\\(\\mu\\) relation with \\(\\alpha\\) and \\(D_0\\)\nTo interpret these neurons, we look at their relation with the physical parameters we expect in this dataset, the anomalous exponent \\(\\alpha\\) and the constant \\(D_0\\).\nWe observe that both surviving neurons have a not so clear relation with \\(\\alpha\\) while the uninformative neurons remain at zero mean.\n\nplt.plot(alphas_items, mu,'+', alpha=0.1);\nplt.xlabel(r'$\\alpha$'); plt.ylabel(r'$\\mu$ neuron activation');\nplt.grid();\n\n\n\n\n\n\n\n\nFor the constant \\(D_0\\), we have a similar scenario, both neurons present a relation with the parameter.\n\nplt.plot(Ds_items, mu,'+', alpha=0.1);\nplt.xlabel(r'$D_0$'); plt.ylabel(r'$\\mu$ neuron activation');\nplt.xscale('log'); plt.grid();\n\n\n\n\n\n\n\n\nIn this case, the interpretation is not satisfactory considering only the independent parameters that control the whole expression of the aging diffusion coefficient \\[D_\\alpha(t) = \\alpha D_0 t^{\\alpha-1}.\\] Instead, the latent neurons are encoding both parameters with two combinations.\nOne of the neurons holds a strong relation with \\(\\log (D_\\alpha(t=T)) = \\log(\\alpha D_0 T^{\\alpha-1})\\).\n\nplt.plot(np.log(alphas_items*Ds_items*400**(alphas_items-1)), mu,'+', alpha=0.1);\nplt.xlabel(r'$\\log (D_\\alpha(t=T)) = \\log(\\alpha D_0 T^{\\alpha-1})$');\nplt.ylabel(r'$\\mu$ neuron activation');\n\n\n\n\n\n\n\n\nThe other neuron is similar to \\(\\log(\\alpha D_0 T^{-(\\alpha-1)})\\).\n\nplt.plot(np.log(alphas_items*Ds_items*400**(1-alphas_items)), mu,'+', alpha=0.1);\nplt.xlabel(r'$\\log (\\alpha D_0 T^{-(\\alpha-1)})$'); plt.ylabel(r'$\\mu$ neuron activation');\n\n\n\n\n\n\n\n\nTo properly observe the relation of the latent neurons with the parameters, we show the distribution of the surviving neurons’ activations relative to the parameters alone and to their combinations. This constitutes an example of the Fig. 2 in our paper.\n\ncmap_latent = 'Blues'\n\n\nmu_idx = 2\nplt.hist2d(Ds_items, mu[:,mu_idx].numpy(),\n           bins=(u_D,125), cmin=2, cmap=cmap_latent,\n           norm = matplotlib.colors.LogNorm());\nplt.xscale('log');\nplt.xlabel(r'$D$');plt.ylabel(r'$\\mu_' f'{mu_idx}' '$');\nplt.grid();\n\n\n\n\n\n\n\n\n\nmu_idx = 0\nplt.hist2d(alphas_items, mu[:,mu_idx].numpy(),\n           bins=(u_a,125), cmin=2, cmap=cmap_latent,\n           norm = matplotlib.colors.LogNorm());\nplt.xlabel(r'$\\alpha$');plt.ylabel(r'$\\mu_' f'{mu_idx}' '$');\nplt.grid();\n\n\n\n\n\n\n\n\n\nmu_idx = 2\nplt.hist2d(np.log(alphas_items*Ds_items*400**(alphas_items-1)), mu[:,mu_idx].numpy(),\n           125, cmin=2, cmap=cmap_latent, norm = matplotlib.colors.LogNorm());\nplt.xlabel(r'$\\log (D_\\alpha(t=T)) = \\log(\\alpha D_0 T^{\\alpha-1})$');\nplt.ylabel(r'$\\mu_' f'{mu_idx}' '$');\n\n\n\n\n\n\n\n\n\nmu_idx = 0\nplt.hist2d(np.log(alphas_items*Ds_items*400**(1-alphas_items)), mu[:,mu_idx].numpy(),\n           125, cmin=2, cmap=cmap_latent, norm = matplotlib.colors.LogNorm());\nplt.xlabel(r'$ \\log(\\alpha D_0 T^{-(\\alpha-1)})$');\nplt.ylabel(r'$\\mu_' f'{mu_idx}' '$');\n\n\n\n\n\n\n\n\nThe surviving neurons respectively exhibit an almost linear relationship with the combinations above.\nTo discern how combined this representation is, the next figure shows \\(\\mu_i\\) with respect to both parameters at the same time.\n\nfig, axs = plt.subplots(3,2, subplot_kw={'projection':'3d'},figsize=(6,8))\nfor mu_idx in range(mu.shape[-1]):\n    Z = np.empty((len(u_a), len(u_D)))\n    for j,D in enumerate(u_D):\n        for i,a in enumerate(u_a):\n            Z[i,j] = mu[intersect_idx[i,j],mu_idx].mean()\n    Z = Z.T\n    \n    ax = axs.flat[mu_idx]\n    X = u_a; Y = np.log10(u_D)\n    X, Y = np.meshgrid(X, Y)\n    cmap_latent_3d = matplotlib.cm.viridis\n    norm_3d = matplotlib.colors.Normalize(vmin=-4,vmax=4)\n    surf = ax.plot_surface(X, Y, Z, cmap=cmap_latent_3d,norm=norm_3d, alpha=0.6,\n                           rstride=3, cstride=3,\n                           linewidth=0, antialiased=False,)\n    ax.xaxis.set_rotate_label(False)  # disable automatic rotation\n    ax.set_xlabel(r'$\\alpha$', labelpad=-8,rotation=0,ha='right',va='center');\n    ax.set_xticks([0,1,2],[0,1,2],ha='right',va='center', )#rotation_mode='anchor')\n    ax.set_xlim([0,2]);ax.set_ylim(np.log10([3.16e-6,3.163e-2]));\n    ax.yaxis.set_rotate_label(False)  # disable automatic rotation\n    ax.set_ylabel(r'$D$', labelpad=-4,rotation=0,ha='left',va='bottom');\n    ax.set_yticks([-5,-4,-3,-2],[r'$10^{-5}$','',r'$10^{-3}$',''],ha='left',va='center');\n    ax.tick_params(pad=-6)\n    ax.yaxis.set_tick_params(pad=-4)\n    ax.xaxis.set_tick_params(pad=-4)\n    ax.zaxis.set_tick_params(pad=-6)\n    ax.zaxis.set_rotate_label(False)  # disable automatic rotation\n    ax.set_zlabel(r'$z_{_' f'{mu_idx}' r'}$',rotation=0,labelpad=-8, va='center', ha='right')\n    ax.set_zlim(-3,3);\n    ax.set_zticks([-2,0,2],[r'$-2$',r'$0$',r'$2$'], ha='right', va='center')\n    ax.set_box_aspect(None, zoom=1)\n    ax.zaxis._axinfo['juggled'] = (1,2,0)\n    ax.tick_params(axis='x', which='major', direction='in')\n    ax.tick_params(axis='y', which='major', direction='in')\n    ax.tick_params(axis='z', which='major', direction='in')\n\n\n\n\n\n\n\n\nIn the following generation tutorial, we will observe how we can generate trajectories that exhibit these relationships with \\(\\alpha\\) and \\(D\\).",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Analyzing SBM"
    ]
  },
  {
    "objectID": "tutorials/analysis_fbm.html",
    "href": "tutorials/analysis_fbm.html",
    "title": "Analyzing FBM",
    "section": "",
    "text": "In this notebook, we aim at visualizing what the trained SPIVAE learned. We look into the output, the latent neurons, and the loss distribution of the model.",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Analyzing FBM"
    ]
  },
  {
    "objectID": "tutorials/analysis_fbm.html#latent-neuron-activations-distribution",
    "href": "tutorials/analysis_fbm.html#latent-neuron-activations-distribution",
    "title": "Analyzing FBM",
    "section": "Latent neuron activations distribution",
    "text": "Latent neuron activations distribution\nThe following plots show the distribution of the mean and variance activations. Two neurons have a spread mean and very small variances, while the rest of neurons’ activations lie around zero mean and unit variance. Colors indicate each latent neuron index.\n\nfig, axs = plt.subplots(1,2,sharey=True,gridspec_kw=dict(wspace=0));\naxs[0].hist(mu.T, 100, histtype='step', log=True);\naxs[0].set_xlabel(r'$\\mu$ neuron activation');\naxs[0].set_ylabel('Counts');\naxs[1].hist(np.exp(logvar).T, 100, histtype='step', log=True);\naxs[1].set_xlabel(r'$\\sigma^2$ neuron activation');\n\n\n\n\n\n\n\n\nWe can also detect which neurons are being informative with simple metrics. For instance, the authors of Lu et al. Phys. Rev. X 10, 031056 make use of two quantities to distinguish such neurons, the variance of the mean, and the mean of the variance (we use here the logarithm for visual convenience).\n\nplt.plot(mu.var(0), label=r'Var($\\mu$)');\nplt.plot(logvar.mean(0), label=r'Mean($\\log\\sigma^2$)');\nplt.xlabel('Latent neuron index'); plt.legend();",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Analyzing FBM"
    ]
  },
  {
    "objectID": "tutorials/analysis_fbm.html#mu-relation-with-alpha-and-d",
    "href": "tutorials/analysis_fbm.html#mu-relation-with-alpha-and-d",
    "title": "Analyzing FBM",
    "section": "\\(\\mu\\) relation with \\(\\alpha\\) and \\(D\\)",
    "text": "\\(\\mu\\) relation with \\(\\alpha\\) and \\(D\\)\nTo interpret these neurons, we look at their relation with the physical parameters we expect in this dataset, the anomalous exponent \\(\\alpha\\) and the generalized diffusion coefficient \\(D\\).\nOne of the two surviving neurons is directly related to \\(\\alpha\\) while the other follows a uniform spread except for big \\(\\alpha\\). The uninformative neurons remain at zero mean.\n\nplt.plot(alphas_items, mu,'+', alpha=0.1);\nplt.xlabel(r'$\\alpha$'); plt.ylabel(r'$\\mu$ neuron activation');\nplt.grid();\n\n\n\n\n\n\n\n\nFor the diffusion coefficient, we have a similar scenario. One neuron shows a strong relationship with \\(D\\), while the neuron, that had a direct relation with \\(\\alpha\\), also shows a relation with small and big \\(D\\).\n\nplt.plot(Ds_items, mu,'+', alpha=0.1);\nplt.xlabel(r'$D$'); plt.ylabel(r'$\\mu$ neuron activation');\nplt.xscale('log'); plt.grid();\n\n\n\n\n\n\n\n\nTo properly observe the relation of the latent neurons with the parameters, we show the distribution of the surviving neurons’ activations relative to the parameters. This constitutes an example of the Fig. 2 in our paper.\n\ncmap_latent = 'Blues'\n\n\nmu_idx = 0\nplt.hist2d(Ds_items, mu[:,mu_idx].numpy(),\n           bins=(u_D,125), cmin=2, cmap=cmap_latent,\n           norm = matplotlib.colors.LogNorm());\nplt.xscale('log'); plt.grid();\nplt.xlabel(r'$D$'); plt.ylabel(r'$\\mu_' f'{mu_idx}' '$', rotation=0);\n\n\n\n\n\n\n\n\n\nmu_idx = 1\nplt.hist2d(alphas_items, mu[:,mu_idx].numpy(),\n           bins=(u_a,125), cmin=2, cmap=cmap_latent,\n           norm = matplotlib.colors.LogNorm());\nplt.xlabel(r'$\\alpha$'); plt.ylabel(r'$\\mu_' f'{mu_idx}' '$', rotation=0); plt.grid();\n\n\n\n\n\n\n\n\nThe surviving neurons respectively exhibit an almost linear relationship with the parameters \\(D\\) and \\(\\alpha\\) in the training range.\nThe primary reason for the broadening of the distributions above is attributed to the combined representation of the parameters in the latent neurons.\nTo discern how combined this representation is, the next figure shows \\(\\mu_i\\) with respect to both parameters at the same time.\n\nfig, axs = plt.subplots(3,2, subplot_kw={'projection':'3d'},figsize=(6,8))\nfor mu_idx in range(mu.shape[-1]):\n    Z = np.empty((len(u_a), len(u_D)))\n    for j,D in enumerate(u_D):\n        for i,a in enumerate(u_a):\n            Z[i,j] = mu[intersect_idx[i,j],mu_idx].mean()\n    Z = Z.T\n    \n    ax = axs.flat[mu_idx]\n    X = u_a; Y = np.log10(u_D)\n    X, Y = np.meshgrid(X, Y)\n    cmap_latent_3d = matplotlib.cm.viridis\n    norm_3d = matplotlib.colors.Normalize(vmin=-4,vmax=4)\n    surf = ax.plot_surface(X, Y, Z, cmap=cmap_latent_3d,norm=norm_3d, alpha=0.6,\n                           rstride=3, cstride=3,\n                           linewidth=0, antialiased=False,)\n    ax.xaxis.set_rotate_label(False)  # disable automatic rotation\n    ax.set_xlabel(r'$\\alpha$', labelpad=-8,rotation=0,ha='right',va='center');\n    ax.set_xticks([0,1,2],[0,1,2],ha='right',va='center', )#rotation_mode='anchor')\n    ax.set_xlim([0,2]);ax.set_ylim(np.log10([3.16e-6,3.163e-2]));\n    ax.yaxis.set_rotate_label(False)  # disable automatic rotation\n    ax.set_ylabel(r'$D$', labelpad=-4,rotation=0,ha='left',va='bottom');\n    ax.set_yticks([-5,-4,-3,-2],[r'$10^{-5}$','',r'$10^{-3}$',''],ha='left',va='center');\n    ax.tick_params(pad=-6)\n    ax.yaxis.set_tick_params(pad=-4)\n    ax.xaxis.set_tick_params(pad=-4)\n    ax.zaxis.set_tick_params(pad=-6)\n    ax.zaxis.set_rotate_label(False)  # disable automatic rotation\n    ax.set_zlabel(r'$z_{_' f'{mu_idx}' r'}$',rotation=0,labelpad=-8, va='center', ha='right')\n    ax.set_zlim(-3,3);\n    ax.set_zticks([-2,0,2],[r'$-2$',r'$0$',r'$2$'], ha='right', va='center')\n    ax.set_box_aspect(None, zoom=1)\n    ax.zaxis._axinfo['juggled'] = (1,2,0)\n    ax.tick_params(axis='x', which='major', direction='in')\n    ax.tick_params(axis='y', which='major', direction='in')\n    ax.tick_params(axis='z', which='major', direction='in')\n\n\n\n\n\n\n\n\nIn the following generation tutorial, we will observe how selecting values from the latent neurons, we can generate trajectories that exhibit these relationships with \\(\\alpha\\) and \\(D\\).",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Analyzing FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_sbm.html",
    "href": "tutorials/generation_sbm.html",
    "title": "Generation of SBM",
    "section": "",
    "text": "The goal of this tutorial is to generate new trajectories from the trained SPIVAE and examine their attributes to evaluate the model’s strengths and drawbacks.",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Generation of SBM"
    ]
  },
  {
    "objectID": "tutorials/generation_sbm.html#load-generated-displacements",
    "href": "tutorials/generation_sbm.html#load-generated-displacements",
    "title": "Generation of SBM",
    "section": "Load generated displacements",
    "text": "Load generated displacements\nWe first load the generated displacements for the combination of parameters we want.\n\ndisp_gen = {f'{a:.3g}'+f',{D:.3g}':[] for D in ds_args[\"D\"] for a in ds_args[\"alpha\"]}\n\n\nfor a in ds_args[\"alpha\"]:\n    for D in ds_args[\"D\"]:\n        with np.load(f'../../data/gen/'+model_name+f'_disp_gen_a{a:.3g}D{D:.3g}'.replace('.','')+'.npz', allow_pickle=True)\\\n        as f:\n            k = f'{a:.3g}'+f',{D:.3g}'\n            disp_gen[k] = f['disp_gen']",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Generation of SBM"
    ]
  },
  {
    "objectID": "tutorials/generation_sbm.html#check-generated-displacements-mean-and-variance",
    "href": "tutorials/generation_sbm.html#check-generated-displacements-mean-and-variance",
    "title": "Generation of SBM",
    "section": "Check generated displacements mean and variance",
    "text": "Check generated displacements mean and variance\nAs a fast check of the generation, we can see if the displacements mean and variance are the expected. For each parameter combination, we observe the mean of generated displacements is inside the limits we saw with the input.\n\nfor j,D in enumerate(ds_args[\"D\"]):\n    for i,a in enumerate(ds_args[\"alpha\"]):\n        k = f'{a:.3g}'+f',{D:.3g}'\n        plt.plot(disp_gen[k].squeeze().mean(0), '-', c=f'C{i}',label=f'{a:.3g}, {D:.3g}'); \n    plt.xlabel(r'$t$');plt.ylabel(r'$\\mu_{gen}$');\n\n\n\n\n\n\n\n\nFor the variance, we observe a correct reproduction of the scaling with a small deviation, as noted in the analysis.\n\nfor j,D in enumerate(ds_args[\"D\"]):\n    plt.figure()\n    for i,a in enumerate(ds_args[\"alpha\"][::5]):\n        k = f'{a:.3g}'+f',{D:.3g}'\n        # original time\n        t_full = np.arange(1,disp_gen[k].shape[-1]+1)\n        # shifted\n        t_shift = model.receptive_field+1\n        t_gen  = t_full + t_shift\n        # scaling to compensate the time generated by the machine starting at RF+1\n        # time scale factors: ((1+t_full)/(t_shift+t_full))**(a-1.)\n        t_scaling = ((1+t_full)/(t_gen))**(a-1.)              \n        x = sig2D(disp_gen[k].squeeze().std(0))\n        x = x*t_scaling\n        plt.semilogy(x, '-', c=f'C{i}', label=f'{a:.3g}');\n        plt.plot(a*D*np.arange(1,x.shape[-1])**(a-1.), '--')\n    plt.axhline(D, c='k', lw=1, ls='--', alpha=0.7);\n    plt.xlabel(r'$t$');plt.ylabel(r'$D_{gen}$');\n    h,l = plt.gca().get_legend_handles_labels()\n    plt.legend(h[::-1],l[::-1],title=r'$\\alpha$', bbox_to_anchor=(1,1));",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Generation of SBM"
    ]
  },
  {
    "objectID": "tutorials/generation_sbm.html#tea-msd-for-sbm",
    "href": "tutorials/generation_sbm.html#tea-msd-for-sbm",
    "title": "Generation of SBM",
    "section": "TEA-MSD for SBM",
    "text": "TEA-MSD for SBM\nTo extract the anomalous exponent \\(\\alpha\\) from SBM trajectories, one needs the time ensemble average mean squared displacement (TEA-MSD). As SBM is weakly non-ergodic, the TA-MSD along different time lags will not work as it did for FBM. We instead make the TA-MSD for one time lag and take the ensemble average.\n\ndef TAMSD_t_lag(traj, t_lag):\n    t_t_lag = len(traj) - t_lag\n    tamsd = np.zeros(t_t_lag, dtype=np.float64)\n    for t_ in range(t_t_lag): tamsd[t_] = (traj[t_] - traj[t_ + t_lag])**2\n    tamsd /= (t_t_lag)\n    return tamsd\n\ndef TEAMSD_t_lag(trajs, t_lag):\n    ttt = np.zeros((trajs.shape[0], trajs.shape[-1]-t_lag), dtype=np.float64)\n    for i in range(trajs.shape[0]): # prange\n        ttt[i] = TAMSD_t_lag(trajs[i], t_lag)\n    return ttt\n\ndef get_alphas_from_sbm_trajs(trajs, t_lag=2, perc=.55):\n    tamsd_ = TEAMSD_t_lag(trajs,t_lag) # N, T-t_lag\n    log_tamsd_ = np.log(tamsd_)\n    # if two timesteps have the same value, tamsd_=0 and log is -inf and polyfit is nan\n    log_tamsd_[~np.isfinite(log_tamsd_)]=-27\n    log_t = np.log(np.arange(1,tamsd_.shape[-1]+1)) # T-t_lag\n    last_perc = int(log_tamsd_.shape[-1]*perc)\n    return 1.+np.polyfit(log_t[-last_perc:], log_tamsd_[:,-last_perc:].T, 1)[0]\n\n\nexponents = np.zeros((len(ds_args[\"alpha\"]),len(ds_args[\"D\"])))\nfor j,D in enumerate(ds_args[\"D\"]):\n    for i,a in enumerate(ds_args[\"alpha\"]):\n        k = f'{a:.3g}' + f',{D:.3g}'\n        traj  = np.cumsum(disp_gen[k],-1)\n        exponents[i,j] = get_alpha_from_sbm_traj(traj, t_lag=2, perc=.55)\n\n\nfname = '../../data/analysis/'+model_name+'_exponents.npz'\nif not os.path.exists(fname):\n    os.makedirs('../../data/analysis/', exist_ok=True) \n    np.savez_compressed(fname,exponents=exponents)\n\n\nexponents = np.load(fname)[\"exponents\"]\n\n\ncmap_D = matplotlib.colors.ListedColormap(matplotlib.colormaps['Greens'](np.linspace(0.3,1,150)))\nnorm_D = matplotlib.colors.LogNorm(vmin=3.16e-6, vmax=3.16e-2)\nsm_D_4 = plt.cm.ScalarMappable(cmap=cmap_D, norm=norm_D)\n\nfor j,D in enumerate(ds_args[\"D\"]):\n    x = ds_args[\"alpha\"]\n    y = exponents[:,j]\n    plt.plot([0,1,2], 'gray', alpha=0.7, zorder=-1);\n    plt.plot(x,y, c=cmap_D(norm_D(D)),label=f'{D:.3g}');\nax = plt.gca(); ax.grid();\nax.set_xlabel(r'$\\alpha$', ha='center', va='top',);\nax.set_ylabel(r'$\\alpha_{g}$', rotation=0, ha='right', va='center');\nax.set_xlim(0,2); ax.set_ylim(0,2);\n\nax.locator_params(nbins=3);\nax.set_xticks([0.2,1,1.8],[0.2,'1',1.8])\n\ncb = plt.colorbar(sm_D_4, ax=ax,pad=0, aspect=9,shrink=0.3, anchor=(-2,0.125));\ncb.ax.set_ylabel(r'$D_0$',ha='left', va='center', rotation=0, )\ncb.ax.set_yscale('log')\ncb.ax.set_yticks([1e-5,1e-2], [r'$10^{-5}$',r'$10^{-2}$']);\n\n\n\n\n\n\n\n\nThe estimated exponent \\(\\alpha_g\\) is very close to the ground truth of the input for different values of \\(D_0\\).",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Generation of SBM"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SPIVAE",
    "section": "",
    "text": "Interpretable autoregressive β-VAE architecture.\n\n\n\nSPIVAE is a machine learning method to study stochastic processes. It tries to learn the probability distribution of input trajectories and permits us to interpret its functioning and generate new trajectories with controllable features.\nThe approach was initially devised for the paper entitled Learning minimal representations of stochastic processes with variational autoencoders. We provide a documented library and detailed tutorials to facilitate the reproduction of our research findings.\n\nGetting started\nTo use this code as a library, you will need a system with python&gt;=3.10 and proceed with the installation. You can install SPIVAE by first cloning this repository in your file system:\ngit clone https://github.com/GabrielFernandezFernandez/SPIVAE.git\ncd SPIVAE\npip install .\nThis will install all the necessary dependencies to make full use of the library. Make sure your file system has enough space to store the data files of some GBs.\n\n\nCite us\nIf you use this library, please give us credit.\n@misc{fernandez2023learning,\n  title = {Learning Minimal Representations of Stochastic Processes with Variational Autoencoders},\n  author = {{Fern{\\'a}ndez-Fern{\\'a}ndez}, Gabriel and Manzo, Carlo and Lewenstein, Maciej and Dauphin, Alexandre and {Mu{\\~n}oz-Gil}, Gorka},\n  year = {2023},\n  month = jul,\n  number = {arXiv:2307.11608},\n  eprint = {2307.11608},\n  publisher = {{arXiv}},\n  doi = {10.48550/arXiv.2307.11608},\n  url = {http://arxiv.org/abs/2307.11608},\n  keywords  = {Soft Condensed Matter (cond-mat.soft),\n               Machine Learning (cs.LG),\n               Biological Physics (physics.bio-ph),\n               {Data Analysis, Statistics and Probability (physics.data-an)},\n               Quantitative Methods (q-bio.QM)}\n}",
    "crumbs": [
      "SPIVAE"
    ]
  },
  {
    "objectID": "source/data.html",
    "href": "source/data.html",
    "title": "Data",
    "section": "",
    "text": "To study stochastic processes, we take trajectories from three paradigmatic diffusion models: Brownian motion, fractional Brownian motion, and scaled Brownian motion.\nWe generate the trajectories with the andi_datasets package.\n\n\nFor fractional Brownian motion (FBM), we take \\(\\alpha\\in[0.04, 1.96]\\). For the dataset of Brownian motion (BM), we can take directly the FBM trajectories with \\(\\alpha=1\\).\n\nalphas_train = np.linspace(0.2,1.8,21)\nalphas_test = np.linspace(0.04,1.96,49)\nprint(f'{alphas_train=}')\nprint(f'{alphas_test=}')\n\nalphas_train=array([0.2 , 0.28, 0.36, 0.44, 0.52, 0.6 , 0.68, 0.76, 0.84, 0.92, 1.  ,\n       1.08, 1.16, 1.24, 1.32, 1.4 , 1.48, 1.56, 1.64, 1.72, 1.8 ])\nalphas_test=array([0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 , 0.44,\n       0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84, 0.88,\n       0.92, 0.96, 1.  , 1.04, 1.08, 1.12, 1.16, 1.2 , 1.24, 1.28, 1.32,\n       1.36, 1.4 , 1.44, 1.48, 1.52, 1.56, 1.6 , 1.64, 1.68, 1.72, 1.76,\n       1.8 , 1.84, 1.88, 1.92, 1.96])\n\n\nAs advised in the andi_datasets library, we can save at the beginning a big dataset (t_save \\(\\sim 10^3\\) and N_save \\(\\sim 10^4\\)) which then allows us to load any other combination of T and N_models.\n\nAD.avail_models_name\n\n['attm', 'ctrw', 'fbm', 'lw', 'sbm']\n\n\n\nT=400 ;  N=6_000\ndataset = AD.create_dataset(T=T, N_models=N,\n                            exponents=alphas_test,\n                            models=[2],   # fbm\n                            dimension=1,\n                            N_save=N,\n                            t_save=T,\n                            save_trajectories=True,\n                            load_trajectories=False, # False allows saving \n                            path=\"../../data/raw/\")\n\nThe andi_datasets gives us the trajectories with shape \\([N*|\\mathrm{exponents}|, 2+T]\\) where the first two data points of each vector are the model label and the anomalous exponent \\(\\alpha\\).\n\ndataset.shape, dataset[0,:2], dataset[-1,:2]\n\n((294000, 402), array([2.  , 0.04]), array([2.  , 1.96]))\n\n\nThe following \\(T\\) points compose the trajectory that always has zero origin.\n\nplt.plot(dataset[0,2:], label=f'{alphas_test[0]:.3g}');\nplt.plot(dataset[49//2*N,2:], label=f'{alphas_test[49//2]:.3g}');\nplt.plot(dataset[-1,2:], label=f'{alphas_test[-1]:.3g}');\nplt.xlabel(r'$t$');plt.ylabel(r'$x$', rotation=0);\nplt.legend(title=r'$\\alpha$');\n\n\n\n\n\n\n\n\nThe distribution of the positions \\(x(t)\\) depends on \\(\\alpha\\) and time, as we expect from the mean squared displacement relation \\(\\langle x^2\\rangle=2 D t^\\alpha\\).\n\nfig, axs = plt.subplots(3,1, sharex=True, gridspec_kw=dict(hspace=0))\nfor ax, a_i in zip(axs,[0,49//2,48]):\n    ax.hist2d(np.tile(np.arange(T),N),dataset[a_i*N:(a_i+1)*N,2:].reshape(-1), T, cmin=2, norm=matplotlib.colors.LogNorm());\n    ax.text(0.02,0.9, r'$\\alpha=' f'{dataset[a_i*N,1]:.3g}' r'$', transform=ax.transAxes);\n    ax.set_ylabel(r'$x$', rotation=0);\n    ax.set_ylim([-4,4])\n    ax.locator_params(nbins=3);\naxs[-1].set_xlabel(r'$t$');\n\n\n\n\n\n\n\n\nConveniently, the displacements \\(\\Delta x\\) are stationary.\n\nfig, axs = plt.subplots(3,1, sharex=True, gridspec_kw=dict(hspace=0))\nfor ax, a_i in zip(axs,[0,49//2,48]):\n    ax.hist2d(np.tile(np.arange(T-1),N),np.subtract(dataset[a_i*N:(a_i+1)*N,3:],dataset[a_i*N:(a_i+1)*N,2:-1]).reshape(-1), T-1, cmin=2, norm=matplotlib.colors.LogNorm());\n    ax.text(0.02,0.9, r'$\\alpha=' f'{dataset[a_i*N,1]:.3g}' r'$', transform=ax.transAxes);\naxs[-1].set_xlabel(r'$t$');\nfor ax in axs : ax.set_ylabel(r'$\\Delta x$', rotation=0);\n\n\n\n\n\n\n\n\n\n\n\nFor the generation of scaled Brownian motion (SBM) trajectories, we take the generating function from andi_datasets to control sigma as \\(D_0\\) and generate displacements directly.\n\nsource\n\n\n\n sbm (T, alpha, sigma=1)\n\nCreates T scaled Brownian motion displacements\nWe select the range of values to coincide with the previous dataset.\n\nT=400; N=1_000\nDs = np.geomspace(1e-5,1e-2, 10)\nalphas_train = np.linspace(0.2,1.8,21)\n\n\ndisp = {f'{a:.3g}'+f',{D:.3g}':[] for D in Ds for a in alphas_train}\nfname = '../../data/raw/sbm.npz'\nif not os.path.exists(fname):  # create\n    for i,a in enumerate(alphas_train):\n        for j,D in enumerate(Ds):\n            k = f'{a:.3g}'+f',{D:.3g}'\n            disp[k]=np.array([np.concatenate(([a,D],sbm(T, a, sigma = D2sig(D)))) for n in range(N)]) # N, T+2\n    np.savez_compressed(fname,**disp)\n    print('Saved at:', fname)\nelse:  # load\n    with np.load(fname) as f:\n        for i,a in enumerate(alphas_train):\n            for j,D in enumerate(Ds):\n                k = f'{a:.3g}'+f',{D:.3g}'\n                disp[k] = f[k][:N,:2+T]\n    print('Loaded from:', fname)\n\nLoaded from: ../../data/raw/sbm.npz\n\n\nThe displacements follow the temporal scaling \\(D_\\alpha(t) = \\alpha D_0 t^{\\alpha-1}\\).\n\nfig, axs = plt.subplots(3,1, sharex=True, gridspec_kw=dict(hspace=0))\nfor ax, a in zip(axs,[0.2,1,1.8]):\n    k = f'{a:.3g}'+f',0.01'\n    ax.hist2d(np.tile(np.arange(T),N),disp[k][:,2:].reshape(-1), T, cmin=2, norm=matplotlib.colors.LogNorm());\n    ax.text(0.02,0.9, r'$\\alpha=' f'{a:.3g}' r'$', transform=ax.transAxes);\n    ax.set_ylabel(r'$\\Delta x$', rotation=0);\naxs[-1].set_xlabel(r'$t$');\n\n\n\n\n\n\n\n\nWe can do the same to create a test set.\n\nDs = np.geomspace(1e-6,1e-1,16)[2:-2] # np.geomspace(1e-6,1e-1,61)[6:-6]\nalphas = np.linspace(0.04,1.96,49)\ndisp_test = {f'{a:.3g}'+f',{D:.3g}':[] for D in Ds for a in alphas_train}\nfname = '../../data/test/sbm.npz'\nif not os.path.exists(fname):  # create\n    os.makedirs('../../data/test/', exist_ok=True)\n    for i,a in enumerate(alphas_train):\n        for j,D in enumerate(Ds):\n            k = f'{a:.3g}'+f',{D:.3g}'\n            disp_test[k]=np.array([np.concatenate(([a,D],sbm(T, a, sigma = D2sig(D)))) for n in range(N)]) # N, T+2\n    np.savez_compressed(fname,**disp_test)\n    print('Saved at:', fname)",
    "crumbs": [
      "Documentation",
      "Data"
    ]
  },
  {
    "objectID": "source/data.html#fractional-brownian-motion",
    "href": "source/data.html#fractional-brownian-motion",
    "title": "Data",
    "section": "",
    "text": "For fractional Brownian motion (FBM), we take \\(\\alpha\\in[0.04, 1.96]\\). For the dataset of Brownian motion (BM), we can take directly the FBM trajectories with \\(\\alpha=1\\).\n\nalphas_train = np.linspace(0.2,1.8,21)\nalphas_test = np.linspace(0.04,1.96,49)\nprint(f'{alphas_train=}')\nprint(f'{alphas_test=}')\n\nalphas_train=array([0.2 , 0.28, 0.36, 0.44, 0.52, 0.6 , 0.68, 0.76, 0.84, 0.92, 1.  ,\n       1.08, 1.16, 1.24, 1.32, 1.4 , 1.48, 1.56, 1.64, 1.72, 1.8 ])\nalphas_test=array([0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 , 0.44,\n       0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84, 0.88,\n       0.92, 0.96, 1.  , 1.04, 1.08, 1.12, 1.16, 1.2 , 1.24, 1.28, 1.32,\n       1.36, 1.4 , 1.44, 1.48, 1.52, 1.56, 1.6 , 1.64, 1.68, 1.72, 1.76,\n       1.8 , 1.84, 1.88, 1.92, 1.96])\n\n\nAs advised in the andi_datasets library, we can save at the beginning a big dataset (t_save \\(\\sim 10^3\\) and N_save \\(\\sim 10^4\\)) which then allows us to load any other combination of T and N_models.\n\nAD.avail_models_name\n\n['attm', 'ctrw', 'fbm', 'lw', 'sbm']\n\n\n\nT=400 ;  N=6_000\ndataset = AD.create_dataset(T=T, N_models=N,\n                            exponents=alphas_test,\n                            models=[2],   # fbm\n                            dimension=1,\n                            N_save=N,\n                            t_save=T,\n                            save_trajectories=True,\n                            load_trajectories=False, # False allows saving \n                            path=\"../../data/raw/\")\n\nThe andi_datasets gives us the trajectories with shape \\([N*|\\mathrm{exponents}|, 2+T]\\) where the first two data points of each vector are the model label and the anomalous exponent \\(\\alpha\\).\n\ndataset.shape, dataset[0,:2], dataset[-1,:2]\n\n((294000, 402), array([2.  , 0.04]), array([2.  , 1.96]))\n\n\nThe following \\(T\\) points compose the trajectory that always has zero origin.\n\nplt.plot(dataset[0,2:], label=f'{alphas_test[0]:.3g}');\nplt.plot(dataset[49//2*N,2:], label=f'{alphas_test[49//2]:.3g}');\nplt.plot(dataset[-1,2:], label=f'{alphas_test[-1]:.3g}');\nplt.xlabel(r'$t$');plt.ylabel(r'$x$', rotation=0);\nplt.legend(title=r'$\\alpha$');\n\n\n\n\n\n\n\n\nThe distribution of the positions \\(x(t)\\) depends on \\(\\alpha\\) and time, as we expect from the mean squared displacement relation \\(\\langle x^2\\rangle=2 D t^\\alpha\\).\n\nfig, axs = plt.subplots(3,1, sharex=True, gridspec_kw=dict(hspace=0))\nfor ax, a_i in zip(axs,[0,49//2,48]):\n    ax.hist2d(np.tile(np.arange(T),N),dataset[a_i*N:(a_i+1)*N,2:].reshape(-1), T, cmin=2, norm=matplotlib.colors.LogNorm());\n    ax.text(0.02,0.9, r'$\\alpha=' f'{dataset[a_i*N,1]:.3g}' r'$', transform=ax.transAxes);\n    ax.set_ylabel(r'$x$', rotation=0);\n    ax.set_ylim([-4,4])\n    ax.locator_params(nbins=3);\naxs[-1].set_xlabel(r'$t$');\n\n\n\n\n\n\n\n\nConveniently, the displacements \\(\\Delta x\\) are stationary.\n\nfig, axs = plt.subplots(3,1, sharex=True, gridspec_kw=dict(hspace=0))\nfor ax, a_i in zip(axs,[0,49//2,48]):\n    ax.hist2d(np.tile(np.arange(T-1),N),np.subtract(dataset[a_i*N:(a_i+1)*N,3:],dataset[a_i*N:(a_i+1)*N,2:-1]).reshape(-1), T-1, cmin=2, norm=matplotlib.colors.LogNorm());\n    ax.text(0.02,0.9, r'$\\alpha=' f'{dataset[a_i*N,1]:.3g}' r'$', transform=ax.transAxes);\naxs[-1].set_xlabel(r'$t$');\nfor ax in axs : ax.set_ylabel(r'$\\Delta x$', rotation=0);",
    "crumbs": [
      "Documentation",
      "Data"
    ]
  },
  {
    "objectID": "source/data.html#scaled-brownian-motion",
    "href": "source/data.html#scaled-brownian-motion",
    "title": "Data",
    "section": "",
    "text": "For the generation of scaled Brownian motion (SBM) trajectories, we take the generating function from andi_datasets to control sigma as \\(D_0\\) and generate displacements directly.\n\nsource\n\n\n\n sbm (T, alpha, sigma=1)\n\nCreates T scaled Brownian motion displacements\nWe select the range of values to coincide with the previous dataset.\n\nT=400; N=1_000\nDs = np.geomspace(1e-5,1e-2, 10)\nalphas_train = np.linspace(0.2,1.8,21)\n\n\ndisp = {f'{a:.3g}'+f',{D:.3g}':[] for D in Ds for a in alphas_train}\nfname = '../../data/raw/sbm.npz'\nif not os.path.exists(fname):  # create\n    for i,a in enumerate(alphas_train):\n        for j,D in enumerate(Ds):\n            k = f'{a:.3g}'+f',{D:.3g}'\n            disp[k]=np.array([np.concatenate(([a,D],sbm(T, a, sigma = D2sig(D)))) for n in range(N)]) # N, T+2\n    np.savez_compressed(fname,**disp)\n    print('Saved at:', fname)\nelse:  # load\n    with np.load(fname) as f:\n        for i,a in enumerate(alphas_train):\n            for j,D in enumerate(Ds):\n                k = f'{a:.3g}'+f',{D:.3g}'\n                disp[k] = f[k][:N,:2+T]\n    print('Loaded from:', fname)\n\nLoaded from: ../../data/raw/sbm.npz\n\n\nThe displacements follow the temporal scaling \\(D_\\alpha(t) = \\alpha D_0 t^{\\alpha-1}\\).\n\nfig, axs = plt.subplots(3,1, sharex=True, gridspec_kw=dict(hspace=0))\nfor ax, a in zip(axs,[0.2,1,1.8]):\n    k = f'{a:.3g}'+f',0.01'\n    ax.hist2d(np.tile(np.arange(T),N),disp[k][:,2:].reshape(-1), T, cmin=2, norm=matplotlib.colors.LogNorm());\n    ax.text(0.02,0.9, r'$\\alpha=' f'{a:.3g}' r'$', transform=ax.transAxes);\n    ax.set_ylabel(r'$\\Delta x$', rotation=0);\naxs[-1].set_xlabel(r'$t$');\n\n\n\n\n\n\n\n\nWe can do the same to create a test set.\n\nDs = np.geomspace(1e-6,1e-1,16)[2:-2] # np.geomspace(1e-6,1e-1,61)[6:-6]\nalphas = np.linspace(0.04,1.96,49)\ndisp_test = {f'{a:.3g}'+f',{D:.3g}':[] for D in Ds for a in alphas_train}\nfname = '../../data/test/sbm.npz'\nif not os.path.exists(fname):  # create\n    os.makedirs('../../data/test/', exist_ok=True)\n    for i,a in enumerate(alphas_train):\n        for j,D in enumerate(Ds):\n            k = f'{a:.3g}'+f',{D:.3g}'\n            disp_test[k]=np.array([np.concatenate(([a,D],sbm(T, a, sigma = D2sig(D)))) for n in range(N)]) # N, T+2\n    np.savez_compressed(fname,**disp_test)\n    print('Saved at:', fname)",
    "crumbs": [
      "Documentation",
      "Data"
    ]
  },
  {
    "objectID": "source/data.html#fbm",
    "href": "source/data.html#fbm",
    "title": "Data",
    "section": "FBM",
    "text": "FBM\nTo load the dataset of FBM, we simply specify the dataset parameters in a dict and call load_data with it.\n\nDs     = [1e-4, 1e-3, 1e-2]\nalphas = [0.6, 1.0, 1.4]\nn_alphas, n_Ds = len(alphas), len(Ds)\nds_args = dict(path=\"../../data/raw/\", model='fbm', # 'sbm'\n               N=int(6_000/n_alphas/n_Ds), T=400,\n               D=Ds, alpha=alphas,\n               N_save=6_000, T_save=400,\n               seed=0, valid_pct=0.2, bs=2**8,\n              )\ndls = load_data(ds_args)\n\nOnce loaded, we can inspect the data that bring the DataLoaders.\n\nprint(dls.bs, dls.device, len(dls.one_batch()))\nprint(L(map(lambda x: x.shape, dls.one_batch())))\n#print(dls.one_batch())\n\n256 cpu 2\n[torch.Size([256, 1, 399]), torch.Size([256, 399, 1])]\n\n\n\nalphas_items = dls.valid.items[:,0]\nDs_items     = dls.valid.items[:,1]\nds_in_labels = dls.valid.items[:,:2] \nu_a=np.unique(alphas_items,)\nu_D=np.unique(Ds_items,)\nalphas_idx = [np.flatnonzero(alphas_items==a) for a in u_a]\nDs_idx = [np.flatnonzero(Ds_items==D) for D in u_D]\nintersect_idx = np.array([[reduce(partial(np.intersect1d,assume_unique=True),\n                                       (alphas_idx[i],Ds_idx[j]))\n                                for j,D in enumerate(u_D)] for i,a in enumerate(u_a)], dtype=object)\n\nWe fetch the preprocessed dataset as the model will see in the following loop.\n\nds_in = []\nwith torch.no_grad():\n    for b in tqdm(dls.valid):\n        x,y=b\n        ds_in.append(to_detach(x).numpy())\nds_in = np.concatenate(ds_in)\nprint(ds_in.shape)\n\n\n\n\n(1198, 1, 399)\n\n\nThe samples are the displacements \\(\\Delta x\\) of a trajectory.\n\nplt.plot(ds_in.squeeze()[:2].T); plt.xlabel(r'$t$'); plt.ylabel(r'$\\Delta x$', rotation=0);\n\n\n\n\n\n\n\n\nFBM displacements follow a Gaussian distribution \\(\\mathcal{N}(\\mu, \\sigma^2)\\) which is centered at \\(\\mu=0\\) and whose variance is related to the diffusion coefficient as \\(\\sigma^2 = 2D\\).\n\nfor i,D in enumerate(u_D): plt.hist(ds_in[Ds_idx[i]].reshape(-1),500, histtype='step', label=f'{D:.2g}');\nplt.ylabel('Counts'); plt.xlabel(r'$\\Delta x$'); plt.legend(title=r'$D$');\n\n\n\n\n\n\n\n\n\nsource\n\nset_plot_xf\n\n set_plot_xf (x_label='', y_label='', title='', x_scale='linear',\n              y_scale='linear', legend_title='', save=False, ncol=1,\n              show_legend=True)\n\n\nsource\n\n\nplot_xf_D\n\n plot_xf_D (x, f, ds_args, intersect_idx, f_a=None, f_D=None, f_aD=None,\n            each_D=True, each_g=True, **kwargs)\n\nPlots f(x) using the provided indices and auxiliary functions\n\nsource\n\n\nf_a_text\n\n f_a_text (a, y)\n\n\nsource\n\n\nplot_xf\n\n plot_xf (x, f, ds_args, intersect_idx, x_label='', y_label='', title='',\n          x_scale='linear', y_scale='linear')\n\nPlots f(x) using the provided indices\nTherefore, the mean and variance of the displacements constitute two straightforward sanity checks that the generated displacements must satisfy.\n\nplot_xf(ds_in, lambda x: x.squeeze().mean(0),ds_args, intersect_idx, x_label=r'$t$', y_label=r'$\\mu_{in}$',)\n\n\n\n\n\n\n\n\n\nplot_xf_D(ds_in, lambda x: sig2D(x.squeeze().std(0)),ds_args, intersect_idx,\n          f_a=f_a_text,\n          f_D=lambda D: plt.axhline(D, c='k', lw=1, ls='--', alpha=0.7),\n          each_D=False,each_g=False, x_label=r'$t$', y_label=r'$D_{in}$',\n          y_scale='log', show_legend=False,\n         )",
    "crumbs": [
      "Documentation",
      "Data"
    ]
  },
  {
    "objectID": "source/data.html#sbm-1",
    "href": "source/data.html#sbm-1",
    "title": "Data",
    "section": "SBM",
    "text": "SBM\nSimilarly, to load the dataset of SBM, we simply specify the dataset parameters in a dict and call load_data with it.\n\nDs = [1e-5,1e-4,1e-3, 1e-2]  # np.geomspace(1e-5,1e-2, 10) \nalphas = np.linspace(0.2,1.8,21)\nn_alphas, n_Ds = len(alphas), len(Ds)\nds_args = dict(path=\"../../data/raw/\", model='sbm',\n               N=int(100_000/n_alphas/n_Ds/2), T=400,\n               D=Ds, alpha=alphas,\n               N_save=1_000, T_save=400,\n               seed=0, valid_pct=0.2, bs=2**8,)\n\n\ndls = load_data(ds_args)\n\nAs we did before, we can inspect the data that brings the DataLoaders.\n\nalphas_items = dls.valid.items[:,0]\nDs_items     = dls.valid.items[:,1]\nds_in_labels = dls.valid.items[:,:2] \nu_a=np.unique(alphas_items,)\nu_D=np.unique(Ds_items,)\nalphas_idx = [np.flatnonzero(alphas_items==a) for a in u_a]\nDs_idx = [np.flatnonzero(Ds_items==D) for D in u_D]\nintersect_idx = np.array([[reduce(partial(np.intersect1d,assume_unique=True),\n                                       (alphas_idx[i],Ds_idx[j]))\n                                for j,D in enumerate(u_D)] for i,a in enumerate(u_a)], dtype=object)\n\n\nds_in = []\nwith torch.no_grad():\n    for b in tqdm(dls.valid):\n        x,y=b\n        ds_in.append(to_detach(x).numpy())\nds_in = np.concatenate(ds_in)\nprint(ds_in.shape)\n\n\n\n\n(9996, 1, 399)\n\n\nSBM displacements have a zero mean but follow the scaling of the aging diffusion coefficient \\(D_\\alpha (t) = \\alpha D_0 t^{\\alpha-1}\\).\n\nplt.plot(ds_in.squeeze()[:2].T); plt.xlabel(r'$t$'); plt.ylabel(r'$\\Delta x$', rotation=0);\n\n\n\n\n\n\n\n\nFor \\(\\alpha&lt;1\\), the displacements become smaller as time passes. On the contrary, \\(\\alpha&gt;1\\) leads to a growth of the displacements.\n\nfig, axs = plt.subplots(3,1, sharex=True, gridspec_kw=dict(hspace=0))\nfor ax, a_i in zip(axs,[0,10,20]):\n    x = ds_in.squeeze()[alphas_idx[a_i]]\n    ax.hist2d(np.tile(np.arange(x.shape[-1]),x.shape[0]),x.reshape(-1),x.shape[-1],\n              cmin=2, norm=matplotlib.colors.LogNorm());\n    ax.text(0.02,0.9, r'$\\alpha=' f'{u_a[a_i]:.3g}' r'$', transform=ax.transAxes);\n    ax.set_ylabel(r'$\\Delta x$', rotation=0);\naxs[-1].set_xlabel(r'$t$');\n\n\n\n\n\n\n\n\nWe plot the means of the displacements.\n\nplot_xf(ds_in, lambda x: x.squeeze().mean(0),ds_args, intersect_idx, x_label=r'$t$', y_label=r'$\\mu_{in}$',)\n\n\n\n\n\n\n\n\nIn SBM, each \\(\\alpha\\) is shown in the variance at each time step. Thus, this simple sanity check is now a direct observation of the displacements properties.\n\nx = ds_in.squeeze()\nplot_xf_D(x, lambda x: sig2D(x.squeeze().std(0)),ds_args, intersect_idx,\n          f_a=lambda a,y: plt.text(0.95,y[-10],f'{a:.3g}', transform=matplotlib.transforms.blended_transform_factory(plt.gca().transAxes, plt.gca().transData)),\n          f_D=lambda D: plt.axhline(D, c='k', lw=1, ls='--', alpha=0.7),\n          f_aD=lambda a,D: plt.plot(a*D*np.arange(1,x.shape[-1])**(a-1.)),\n          each_D=True,each_g=False, x_label=r'$t$', y_label=r'$D_{in}$',\n          y_scale='log', show_legend=False,\n         )",
    "crumbs": [
      "Documentation",
      "Data"
    ]
  },
  {
    "objectID": "source/models.html",
    "href": "source/models.html",
    "title": "Model",
    "section": "",
    "text": "The architecture of the interpretable autoregressive \\(\\beta\\)-VAE works in the following manner: Given the displacements \\(\\mathbf{\\Delta x}(t)\\) of a diffusion trajectory, the encoder (orange) compresses them into an interpretable latent space (blue), in which few neurons (dark blue) represent physical features of the input data while others are noised out (light blue). An autoregressive decoder (green) generates from this latent representation the displacements \\(\\mathbf{\\Delta x}'(t)\\) of a new trajectory recursively, considering a certain receptive field RF (light green cone). \n\nInitialization\nAs the architecture can be quite deep, a careful initialization is needed (see weight_init function in the model class). We initialize the weights with normal Kaiming init in fan_out mode, taking into account that we use the nonlinear activation function ReLU.\n\nsource\n\ninit_cnn\n\n init_cnn (m)\n\nInitialize weights with kaiming normal in fan_out mode and bias to 0\n\n\n\nVAE\nWe implement a 1D convolutional variational autoencoder.\nThe latent neurons are probabilistic, i.e., they are sampled following a distribution. The reparameterization trick provides the means to allow backpropagation by externalizing the sampling noise.\n\nsource\n\nreparameterize\n\n reparameterize (mu, logvar)\n\nSamples from a normal distribution using the reparameterization trick.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmu\ntorch.Tensor\nMean of the normal distribution. Shape (batch_size, latent_dim)\n\n\nlogvar\ntorch.Tensor\nDiagonal log variance of the normal distribution. Shape (batch_size, latent_dim)\n\n\nReturns\ntorch.Tensor\nSampled latent z tensor as \\(z=\\epsilon\\sigma+\\mu\\)\n\n\n\nWe also take into account the sizes after n convolutions are applied to automate the model construction.\n\nsource\n\n\noutput_size_after_n_convt\n\n output_size_after_n_convt (n, input_size, kernel_size, stride=1,\n                            padding=0, output_padding=0, dilation=1)\n\n\nsource\n\n\noutput_size_convt\n\n output_size_convt (input_size, kernel_size, stride=1, padding=0,\n                    output_padding=0, dilation=1)\n\n\nsource\n\n\noutput_size_after_n_conv\n\n output_size_after_n_conv (n, input_size, kernel_size, stride=1,\n                           padding=0, dilation=1)\n\n\nsource\n\n\noutput_size_conv\n\n output_size_conv (input_size, kernel_size, stride=1, padding=0,\n                   dilation=1)\n\n\nsource\n\n\nView\n\n View (size)\n\nUse as (un)flattening layer\n\nsource\n\n\nVAEConv1d\n\n VAEConv1d (nf, encoder, decoder, o_dim:int, nc_in=1, nc_out=6, z_dim=6,\n            beta=0, avg_size=24, **kwargs)\n\n1-dimensional convolutional VAE architecture\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnf\n\n\nnumber of filters\n\n\nencoder\n\n\nlist of Encoder’s dense layers sizes\n\n\ndecoder\n\n\nlist of Decoder’s dense layers sizes\n\n\no_dim\nint\n\ninput size (T)\n\n\nnc_in\nint\n1\nnumber of input channels\n\n\nnc_out\nint\n6\nnumber of output channels\n\n\nz_dim\nint\n6\nnumber of latent neurons\n\n\nbeta\nint\n0\nweight of the KLD loss\n\n\navg_size\nint\n24\noutput size of the pooling layers\n\n\nkwargs\n\n\n\n\n\n\n\n\n\nVAE + WaveNet\nWe implement an extensible version of a VAE with WaveNet as the autoregressive decoder.\n\nsource\n\nsample_from_mix_gaussian\n\n sample_from_mix_gaussian (y, log_scale_min=-12.0)\n\nSample from (discretized) mixture of gaussian distributions\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny\nTensor\n\nMixture of Gaussians parameters. Shape (B x C x T)\n\n\nlog_scale_min\nfloat\n-12.0\nLog scale minimum value.In many other implementations this variable is never used.\n\n\nReturns\nTensor\n\n\n\n\n\n\nsource\n\n\nDilatedCausalConv1d\n\n DilatedCausalConv1d (mask_type, in_channels, out_channels, kernel_size=2,\n                      dilation=1, bias=True, use_pad=True)\n\nDilated causal convolution for WaveNet\n\nsource\n\n\nResidualBlock\n\n ResidualBlock (res_channels, skip_channels, kernel_size, dilation,\n                c_channels=0, g_channels=0, bias=True, use_pad=True)\n\nResidual block with conditions and gate mechanism\n\nsource\n\n\nVAEWaveNet\n\n VAEWaveNet (in_channels=1, res_channels=16, skip_channels=16,\n             c_channels=6, g_channels=0, out_channels=1,\n             res_kernel_size=3, layer_size=4, stack_size=1,\n             out_distribution='normal', discrete_channels=256,\n             num_mixtures=1, use_pad=False, weight_norm=False, **kwargs)\n\nVAE with autoregressive decoder\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nin_channels\nint\n1\ninput channels\n\n\nres_channels\nint\n16\nresidual channels\n\n\nskip_channels\nint\n16\nskip connections channels\n\n\nc_channels\nint\n6\nlocal conditioning\n\n\ng_channels\nint\n0\nglobal conditioning\n\n\nout_channels\nint\n1\noutput channels\n\n\nres_kernel_size\nint\n3\nkernel_size of residual blocks dilated layers\n\n\nlayer_size\nint\n4\nLargest dilation is 2^layer_size\n\n\nstack_size\nint\n1\nnumber of layers stacks\n\n\nout_distribution\nstr\nnormal\n\n\n\ndiscrete_channels\nint\n256\n\n\n\nnum_mixtures\nint\n1\n\n\n\nuse_pad\nbool\nFalse\n\n\n\nweight_norm\nbool\nFalse\n\n\n\nkwargs\n\n\n\n\n\n\nWe can create a model by specifying its parameters in a dict.\n\nmodel_args = dict(# VAE #########################\n                  o_dim=400,\n                  nc_in=1, nc_out=6,\n                  nf=[16]*4,\n                  avg_size=16,\n                  encoder=[200,100],\n                  z_dim=6,\n                  decoder=[100,200],\n                  beta=0,\n                  # WaveNet ########\n                  in_channels=1,\n                  res_channels=16,skip_channels=16,\n                  c_channels=6,\n                  g_channels=0,\n                  res_kernel_size=3,\n                  layer_size=4,  # 6\n                  stack_size=1,\n                  out_distribution= \"Normal\",\n                  num_mixtures=1,\n                  use_pad=False,\n                  model_name = 'SPIVAE',\n                 )\nmodel = VAEWaveNet(**model_args)\n\nPrinting the model object will reveal the declared layers.\n\nmodel\n\nVAEWaveNet(\n  (vae): VAEConv1d(\n    (encoder): Sequential(\n      (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,))\n      (1): ReLU(inplace=True)\n      (2): Conv1d(16, 16, kernel_size=(3,), stride=(1,))\n      (3): ReLU(inplace=True)\n      (4): Conv1d(16, 16, kernel_size=(3,), stride=(1,))\n      (5): ReLU(inplace=True)\n      (6): Conv1d(16, 16, kernel_size=(3,), stride=(1,))\n      (7): ReLU(inplace=True)\n      (8): AdaptiveConcatPool1d(\n        (ap): AdaptiveAvgPool1d(output_size=16)\n        (mp): AdaptiveMaxPool1d(output_size=16)\n      )\n      (9): View()\n      (10): Linear(in_features=512, out_features=200, bias=True)\n      (11): ReLU(inplace=True)\n      (12): Linear(in_features=200, out_features=100, bias=True)\n      (13): ReLU(inplace=True)\n      (14): Linear(in_features=100, out_features=12, bias=True)\n    )\n    (decoder): Sequential(\n      (0): Linear(in_features=6, out_features=100, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Linear(in_features=100, out_features=200, bias=True)\n      (3): ReLU(inplace=True)\n      (4): Linear(in_features=200, out_features=512, bias=True)\n      (5): ReLU(inplace=True)\n      (6): View()\n    )\n    (convt): Sequential(\n      (0): ConvTranspose1d(16, 16, kernel_size=(3,), stride=(1,))\n      (1): ReLU(inplace=True)\n      (2): ConvTranspose1d(16, 16, kernel_size=(3,), stride=(1,))\n      (3): ReLU(inplace=True)\n      (4): ConvTranspose1d(16, 16, kernel_size=(3,), stride=(1,))\n      (5): ReLU(inplace=True)\n      (6): ConvTranspose1d(16, 6, kernel_size=(3,), stride=(1,))\n      (7): ReLU(inplace=True)\n    )\n  )\n  (init_conv): Conv1d(1, 16, kernel_size=(1,), stride=(1,))\n  (causal): DilatedCausalConv1d(\n    (conv): Conv1d(16, 16, kernel_size=(2,), stride=(1,))\n  )\n  (res_stack): ModuleList(\n    (0): ResidualBlock(\n      (dilated): DilatedCausalConv1d(\n        (conv): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n      )\n      (conv_c): Conv1d(6, 32, kernel_size=(1,), stride=(1,), bias=False)\n      (conv_res): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n      (conv_skip): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n    )\n    (1): ResidualBlock(\n      (dilated): DilatedCausalConv1d(\n        (conv): Conv1d(16, 32, kernel_size=(3,), stride=(1,), dilation=(2,))\n      )\n      (conv_c): Conv1d(6, 32, kernel_size=(1,), stride=(1,), bias=False)\n      (conv_res): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n      (conv_skip): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n    )\n    (2): ResidualBlock(\n      (dilated): DilatedCausalConv1d(\n        (conv): Conv1d(16, 32, kernel_size=(3,), stride=(1,), dilation=(4,))\n      )\n      (conv_c): Conv1d(6, 32, kernel_size=(1,), stride=(1,), bias=False)\n      (conv_res): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n      (conv_skip): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n    )\n    (3): ResidualBlock(\n      (dilated): DilatedCausalConv1d(\n        (conv): Conv1d(16, 32, kernel_size=(3,), stride=(1,), dilation=(8,))\n      )\n      (conv_c): Conv1d(6, 32, kernel_size=(1,), stride=(1,), bias=False)\n      (conv_res): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n      (conv_skip): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n    )\n  )\n  (out_conv): Sequential(\n    (0): ReLU(inplace=True)\n    (1): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n    (2): ReLU(inplace=True)\n    (3): Conv1d(16, 9, kernel_size=(1,), stride=(1,))\n  )\n)\n\n\n\n\n\nTraining example\nWith the data and the model, we can already start training.\n\nDEVICE= 'cpu' # 'cuda'\nprint(DEVICE)\n\ncpu\n\n\n\nDs = np.linspace(2e-5,2e-2,10)\nalphas = np.linspace(0.2,1.8,21)\nn_alphas,n_Ds = len(alphas), len(Ds)\nds_args = dict(path=\"../../data/raw/\", model='fbm', # 'sbm'\n               N=int(6_000/n_alphas/n_Ds*2),\n               T=400,\n               D=Ds, alpha=alphas,seed=0,\n               valid_pct=0.2,\n               bs=2**8,\n               N_save=6_000, T_save=400,\n              )\nmodel_args = dict(# VAE ###########################\n                  o_dim=ds_args['T']-1,\n                  nc_in=1, nc_out=6,\n                  nf=[16]*4,\n                  avg_size=16,\n                  encoder=[200,100],\n                  z_dim=6,\n                  decoder=[100,200],\n                  beta=0,\n                  # WaveNet ########\n                  in_channels=1,\n                  res_channels=16,skip_channels=16,\n                  c_channels=6,\n                  g_channels=0,\n                  res_kernel_size=3,\n                  layer_size=4,  # 6  # Largest dilation is 2**layer_size\n                  stack_size=1,\n                  out_distribution= \"Normal\",\n                  num_mixtures=1,\n                  use_pad=False,\n                  model_name = 'SPIVAE',\n                 )\n\n\ndls = load_data(ds_args)\n\n\nmodel = VAEWaveNet(**model_args).to(DEVICE)\n\n\nloss_fn = Loss(model.receptive_field, model.c_channels, \n               beta=model_args['beta'], reduction='mean')\n\n\nlearn = Learner(dls, model, loss_func=loss_fn,)\n\n\nlearn.fit_one_cycle(4, lr_max=1e-4)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.982180\n0.949590\n00:28\n\n\n1\n0.934559\n0.880010\n00:25\n\n\n2\n0.882010\n0.822553\n00:26\n\n\n3\n0.843744\n0.810182\n00:29",
    "crumbs": [
      "Documentation",
      "Model"
    ]
  },
  {
    "objectID": "source/utils.html",
    "href": "source/utils.html",
    "title": "Utils",
    "section": "",
    "text": "source\n\n\n\n Loss (RF, c, use_pad=False, beta=0, reduction='sum')\n\nβ-VAE loss function for a reconstruction term that is the negative log-likelihood of a mixture of Gaussians\n\n\n\n\nsource\n\n\n\n\n mix_gaussian_loss (y_hat, y, log_scale_min=-12.0, reduction='sum')\n\nMixture of continuous Gaussian distributions loss. Note that it is assumed that input is scaled to [-1, 1].\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny_hat\n\n\n\n\n\ny\n\n\n\n\n\nlog_scale_min\nfloat\n-12.0\n\n\n\nreduction\nstr\nsum\n\n\n\nReturns\nTensor\n\nLoss\n\n\n\n\n\n\n\nsource\n\n\n\n\n kl_divergence (mu, logvar, reduction='meansum')\n\nCompute the divergence term of the VAE loss function.",
    "crumbs": [
      "Documentation",
      "Utils"
    ]
  },
  {
    "objectID": "source/utils.html#loss-function",
    "href": "source/utils.html#loss-function",
    "title": "Utils",
    "section": "",
    "text": "source\n\n\n\n Loss (RF, c, use_pad=False, beta=0, reduction='sum')\n\nβ-VAE loss function for a reconstruction term that is the negative log-likelihood of a mixture of Gaussians\n\n\n\n\nsource\n\n\n\n\n mix_gaussian_loss (y_hat, y, log_scale_min=-12.0, reduction='sum')\n\nMixture of continuous Gaussian distributions loss. Note that it is assumed that input is scaled to [-1, 1].\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny_hat\n\n\n\n\n\ny\n\n\n\n\n\nlog_scale_min\nfloat\n-12.0\n\n\n\nreduction\nstr\nsum\n\n\n\nReturns\nTensor\n\nLoss\n\n\n\n\n\n\n\nsource\n\n\n\n\n kl_divergence (mu, logvar, reduction='meansum')\n\nCompute the divergence term of the VAE loss function.",
    "crumbs": [
      "Documentation",
      "Utils"
    ]
  },
  {
    "objectID": "source/utils.html#metrics",
    "href": "source/utils.html#metrics",
    "title": "Utils",
    "section": "Metrics",
    "text": "Metrics\n\nsource\n\nGaussianMixtureMetric\n\n GaussianMixtureMetric (RF:int, c, use_pad:bool=False, func=&lt;function\n                        mix_gaussian_loss&gt;, reduction='mean')\n\nMetric to log the Gaussian mixture loss\n\nsource\n\n\nKLDMetric\n\n KLDMetric (c)\n\nMetric to log the Kullback-Leibler divergence term",
    "crumbs": [
      "Documentation",
      "Utils"
    ]
  },
  {
    "objectID": "source/utils.html#learner-callbacks",
    "href": "source/utils.html#learner-callbacks",
    "title": "Utils",
    "section": "Learner Callbacks",
    "text": "Learner Callbacks\nUtils to get insights from training dynamics.\n\nsource\n\nShowLossCallback\n\n ShowLossCallback (title='')\n\nUpdate a graph of training and validation loss\n\nsource\n\n\nShowKLDsCallback\n\n ShowKLDsCallback (title='')\n\nUpdate a graph of training and validation loss\n\nsource\n\n\nShowLatentsCallback\n\n ShowLatentsCallback (c, title='')\n\nUpdate a graph of latent space\n\nsource\n\n\nKLDsCallback\n\n KLDsCallback (c)\n\nRecord KLD per latent variable\n\nsource\n\n\nplot_klds\n\n plot_klds (learn, start_b=0, title='')\n\n\nsource\n\n\nGMsCallback\n\n GMsCallback (RF, c, use_pad=False, reduction='none')\n\nRecord NLL gaussian mixture log-likelihood means per alpha and D during training",
    "crumbs": [
      "Documentation",
      "Utils"
    ]
  },
  {
    "objectID": "source/utils.html#saveload-models",
    "href": "source/utils.html#saveload-models",
    "title": "Utils",
    "section": "Save/Load models",
    "text": "Save/Load models\n\nsource\n\nsave_model\n\n save_model (fpath, model, model_args, ds_args)\n\n\nsource\n\n\nload_checkpoint\n\n load_checkpoint (fpath, model_class=&lt;class 'SPIVAE.models.VAEWaveNet'&gt;,\n                  device='cuda')",
    "crumbs": [
      "Documentation",
      "Utils"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html",
    "href": "tutorials/generation_fbm.html",
    "title": "Generation of FBM",
    "section": "",
    "text": "The goal of this tutorial is to generate new trajectories from the trained SPIVAE and examine their attributes to evaluate the model’s strengths and drawbacks.",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#load-generated-displacements",
    "href": "tutorials/generation_fbm.html#load-generated-displacements",
    "title": "Generation of FBM",
    "section": "Load generated displacements",
    "text": "Load generated displacements\n\nz_idx = 0\nfname = \"../../data/gen/\"+model_name+f'_disp_gen{z_idx}.npz'\ndisp_gen0 = np.load(fname,)[\"disp_gen\"]\nz_idx = 1\nfname = \"../../data/gen/\"+model_name+f'_disp_gen{z_idx}.npz'\ndisp_gen1 = np.load(fname,)[\"disp_gen\"]",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#check-generated-displacements-mean-and-variance",
    "href": "tutorials/generation_fbm.html#check-generated-displacements-mean-and-variance",
    "title": "Generation of FBM",
    "section": "Check generated displacements mean and variance",
    "text": "Check generated displacements mean and variance\nAs a fast check of the generation, we can see if the displacements mean and variance are the expected. For one neuron, we observe the mean varies more than for the other neuron, coinciding with the interpretation of these neurons with \\(D\\) and \\(\\alpha\\). Both sets of generated displacements have the mean inside the limits we saw with the input.\n\nfig, axs = plt.subplots(1,2, sharey=True, gridspec_kw=dict(wspace=0))\naxs[0].plot(disp_gen0.mean(1).T); axs[1].plot(disp_gen1.mean(1).T);\nfor ax in axs: ax.set_xlabel(r'$t$'); \naxs[0].set_ylabel(r'$\\overline{\\Delta x}_{gen}$');\n\n\n\n\n\n\n\n\nThe same is supported by the variance of the generated displacements, covering the training range of \\(D\\) for one neuron while the other has a baseline with constant margin and some lines with increased \\(D\\).\n\nfig, axs = plt.subplots(1,2, sharey=True, gridspec_kw=dict(wspace=0))\naxs[0].semilogy(sig2D(disp_gen0.std(1)).T);\naxs[1].semilogy(sig2D(disp_gen1.std(1)).T);\nfor ax in axs: ax.set_xlabel(r'$t$'); \naxs[0].set_ylabel(r'$D_{gen}$');\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(1,2, sharey=True, gridspec_kw=dict(wspace=0))\nfor z_i in [0,30,59]:\n    axs[0].hist(disp_gen0[z_i].reshape(-1),100, histtype='step');\n    axs[1].hist(disp_gen1[z_i].reshape(-1),100, histtype='step');\nfor ax in axs: ax.set_xlabel(r'$\\Delta x_{gen}$'); \naxs[0].set_ylabel(r'Counts');",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#correlations",
    "href": "tutorials/generation_fbm.html#correlations",
    "title": "Generation of FBM",
    "section": "Correlations",
    "text": "Correlations\nIn fractional Brownian motion (FBM), the anomalous diffusion arises from the displacements’ correlations. These correlations follow the power-law \\(C\n= |\\langle \\Delta x_t \\Delta x_{t+\\Delta t}\\rangle| /\\Delta x_0^2\n= \\alpha (\\alpha-1) D \\Delta t^{\\alpha-2}\\).\nWhen normalized, the correlations slope in logarithmic scale is a manifestation of the anomalous exponent \\(\\alpha\\).\n\nwindows = int(disp_gen0.shape[-1]*0.8)\ndelta_t = np.arange(1,windows)\n\n\ndisp_gen0.shape\n\n(60, 600, 200)\n\n\n\ndef correlations(disp, windows):\n    return np.array([np.multiply(disp[...,:-win],disp[...,win:]).mean(-1).mean(-1)  # products mean, samples mean\n                      for win in range(1,windows)]).T\n\n\ncorr_mean0 = correlations(disp_gen0, windows)\n\n\ncorr_mean1 = np.array([np.multiply(disp_gen1[:,:,:-win], disp_gen1[:,:,win:]\n                                  ).mean(-1).mean(-1)  # products mean, samples mean\n                      for win in range(1,windows)]).T\n\nIn the following plot, we observe that when varying the first neuron, the slopes remain the same. When varying the other neuron value, we observe different correlations. In the case of big \\(\\alpha\\), it is clear the correlations are maintained until the receptive field.\n\nfig, axs = plt.subplots(1,2, sharey=True, gridspec_kw=dict(wspace=0))\nfor z_i in [0,30,59]:\n    axs[0].loglog(delta_t, np.abs(corr_mean0[z_i]/corr_mean0[z_i,:1]).T);\n    axs[1].loglog(delta_t, np.abs(corr_mean1[z_i]/corr_mean1[z_i,:1]).T);\nfor ax in axs:\n    ax.set_xlabel(r'$\\Delta t$');\n    ax.axvline(learn.model.receptive_field, ls='--', lw=0.2,c='k');\naxs[0].set_ylabel(\"Normalized Absolute Mean\\nof products\" \n           r\" $\\left|\\langle \\Delta x_t\\Delta x_{t+\\Delta t} \\rangle\\right|/\\Delta x_0}^2$\");",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#ta-msd",
    "href": "tutorials/generation_fbm.html#ta-msd",
    "title": "Generation of FBM",
    "section": "TA-MSD",
    "text": "TA-MSD\nOne prevalent approach employed in the study of single-particle diffusion is to estimate the mean squared displacement (MSD) by utilizing the time-averaged mean squared displacement (TA-MSD). We can extract both parameters, \\(\\alpha\\) and \\(D\\), by fitting the scaling of the TA-MSD.\nThe time average mean squared displacement (TA-MSD) can be defined in terms of a trajectory that is sampled at \\(T\\) discrete times \\(t_i = i\\Delta t\\) as, \\[ \\mathrm{TA−MSD}(\\Delta t) =\n\\frac{1}{T − \\Delta t}\n\\sum\\limits^{T −\\Delta t}_{i=1}\n[x(t_i) − x(t_i + \\Delta t)]^2,\n\\] where \\(\\Delta t\\) is the time lag.\n\nfrom numba import njit, prange, set_num_threads\nset_num_threads(2)\n\n# non-jitted version\ndef TMSD_array_(trajs, t_lags):\n    ttt = np.zeros((trajs.shape[0], len(t_lags))) # N trajs, windows\n    for idx, t in enumerate(t_lags):\n        for p in range(trajs.shape[1]-t):\n            ttt[:, idx] += (trajs[:, p]-trajs[:, p+t])**2\n        ttt[:, idx] /= trajs.shape[1]-t\n    return ttt\n\n@njit\ndef TAMSD_(traj, t_lags):\n    tamsd = np.zeros_like(t_lags, dtype=np.float64)\n    for idx, t in enumerate(t_lags):\n        for p in range(len(traj) - t):\n            tamsd[idx] += (traj[p] - traj[p + t])**2\n        tamsd[idx] /= len(traj) - t\n    return tamsd\n\n@njit(parallel=True)\ndef TMSD_array(trajs, t_lags):\n    ttt = np.zeros((trajs.shape[0], len(t_lags)), dtype=np.float64)\n    for i in prange(trajs.shape[0]):\n        ttt[i] = TAMSD_(trajs[i], t_lags)\n    return ttt\n\ndef TAMSD(trajs, t_lags):\n    return TMSD_array(trajs, t_lags)\n\nA common criterion for this technique is to select the initial 10% of the trajectory to perform the fitting.\n\n# first 10%\nskip = 0\nperc = skip + max(4, int(tamsd0.shape[-1]*0.1))-1\n\nlog_delta_t = np.log(delta_t[skip:perc])\nlog_tamsd = np.log(tamsd0[...,skip:perc])\npolyfits = np.array([np.polyfit(log_delta_t, log_tamsd[z_i].T, deg=1)\n                       for z_i in range(z_num)])\ncoeffs0 = 0.5*np.exp(polyfits[:,1])\nexponents0 = polyfits[:,0]\n\nlog_delta_t = np.log(delta_t[skip:perc])\nlog_tamsd = np.log(tamsd1[...,skip:perc])\npolyfits = np.array([np.polyfit(log_delta_t, log_tamsd[z_i].T, deg=1)\n                       for z_i in range(z_num)])\ncoeffs1 = 0.5*np.exp(polyfits[:,1])\nexponents1 = polyfits[:,0]\n\n\nexponents0.shape, exponents1.shape\n\n((60, 600), (60, 600))\n\n\n\ncmap_latent = 'Blues'\n\n\nfig, axs = plt.subplots(1,2, sharey=True,)\nlogbins = np.geomspace(3.16e-6, 3.16e-2,50)\naxs[0].hist2d(coeffs0.reshape(-1),\n           np.repeat(z_range.numpy(),coeffs0.shape[-1]),\n           bins=(logbins,50), cmap=cmap_latent, cmin=2);\naxs[0].set_ylabel(r'$z_0$', rotation=0);\naxs[1].hist2d(coeffs1.reshape(-1),\n           np.repeat(z_range.numpy(),coeffs1.shape[-1]),\n           bins=(logbins,50), cmap=cmap_latent, cmin=2);\naxs[1].set_ylabel(r'$z_1$', rotation=0);\nfor ax in axs:\n    ax.set_xlabel(r'$D_g$'); \n    ax.set_xscale('log');\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(1,2, sharey=True,)\naxs[0].hist2d(exponents0.reshape(-1),\n           np.repeat(z_range.numpy(),exponents0.shape[-1]),\n           bins=(50,z_num), cmap=cmap_latent, cmin=2);\naxs[0].set_ylabel(r'$z_0$', rotation=0);\naxs[1].hist2d(exponents1.reshape(-1),\n           np.repeat(z_range.numpy(),exponents1.shape[-1]),\n           bins=(50,z_num), cmap=cmap_latent, cmin=2);\naxs[1].set_ylabel(r'$z_1$', rotation=0);\nfor ax in axs:\n    ax.set_xlabel(r'$\\alpha_g$');\n    ax.set_xlim([0,2]);\n\n\n\n\n\n\n\n\nIn both cases, each neuron controls mainly one parameter inside the training range. The neuron that represents the anomalous exponent \\(\\alpha\\) also has a bit of effect on \\(D\\).",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#generate-displacements-1",
    "href": "tutorials/generation_fbm.html#generate-displacements-1",
    "title": "Generation of FBM",
    "section": "Generate displacements",
    "text": "Generate displacements\nAs in the previous generation, we load the model trained on trajectories with T=400. Now, instead of generating directly from latent values, we generate from the processed inputs, so we can compare directly with the ground truth.\n\nDEVICE = 'cpu'\nE = 144\nmodel_name = 'fbm' + f'_E{E}'\nc_point, model = load_checkpoint(\"./models/\"+model_name,device=DEVICE)\nds_args, model_args = c_point['ds_args'],c_point['model_args']\nprint(ds_args, model_args)\n\nLoading checkpoint: ./models/fbm_E144.tar\non device: cpu\n{'path': '../../data/raw/', 'model': 'fbm', 'N': 476, 'T': 400, 'D': array([1.00000000e-05, 2.15443469e-05, 4.64158883e-05, 1.00000000e-04,\n       2.15443469e-04, 4.64158883e-04, 1.00000000e-03, 2.15443469e-03,\n       4.64158883e-03, 1.00000000e-02]), 'alpha': array([0.2 , 0.28, 0.36, 0.44, 0.52, 0.6 , 0.68, 0.76, 0.84, 0.92, 1.  ,\n       1.08, 1.16, 1.24, 1.32, 1.4 , 1.48, 1.56, 1.64, 1.72, 1.8 ]), 'seed': 0, 'valid_pct': 0.2, 'bs': 256, 'N_save': 6000, 'T_save': 400} {'o_dim': 399, 'nc_in': 1, 'nc_out': 6, 'nf': [16, 16, 16, 16], 'avg_size': 16, 'encoder': [200, 100], 'z_dim': 6, 'decoder': [100, 200], 'beta': 0.004, 'in_channels': 1, 'res_channels': 16, 'skip_channels': 16, 'c_channels': 6, 'g_channels': 0, 'res_kernel_size': 3, 'layer_size': 4, 'stack_size': 1, 'out_distribution': 'Normal', 'num_mixtures': 1, 'use_pad': False, 'model_name': 'SPIVAE'}\n\n\nWe choose the number of samples for each parameter combination, the number of samples for each processed input, and the batch size for generation.\n\nsamples_per_c = 100\ntrajs_per_aD  = 60\nT_gen = 6_000\ntotal_samples = trajs_per_aD*samples_per_c\nbs = samples_per_c*10\nassert not total_samples%bs, 'Using batched generation mode should be using a multiple of the batch size'\n\nWe should activate the long generation by adding a parameter in the model that sets the upsampling of the latent representation to the desired length.\n\nmodel.vae.Tgen = T_gen+model.receptive_field +1\nprint(model.vae.Tgen)\n\n6033\n\n\nFor the shake of space, we will exemplify the long generation for a single diffusion coefficient.\n\nDs = [1e-3]\nalphas = np.linspace(0.04,1.96,49)\nn_alphas, n_Ds = len(alphas), len(Ds)\n\nAlert! We will generate around 6 GB of data.\n\nprint(f'{32*T_gen*trajs_per_aD*samples_per_c*n_alphas*n_Ds/(8*1024**3):.2} GB')\n\n6.6 GB\n\n\nWe load the dataset to get the upsampled representations.\n\nds_args = dict(path=\"../../data/test/\", model='fbm',\n               N=int(trajs_per_aD*n_Ds*1.4),\n               T=400,\n               D=Ds, alpha=alphas,\n               N_save=1_000, T_save=400,\n               seed=0, valid_pct=.9, bs=2**8,)\n\n\ndls = load_data(ds_args).to(DEVICE)\ndls[0].drop_last, dls[1].drop_last, dls[1].bs, dls.device\n\n(True, False, 256, 'cpu')\n\n\n\nloss_fn = Loss(model.receptive_field, model.c_channels, \n                    beta=model_args['beta'], reduction='mean')\n\nlearn = Learner(dls, model, loss_func=loss_fn, opt_func=Adam,)\nif torch.cuda.is_available() and DEVICE=='cuda': learn.model.cuda()\n\nWe get the upsampled latent representations c and keep track of the parameters.\n\nds_in,preds,ds_targs = learn.get_preds(with_input=True,) # predicts in validation dataset\n\nalphas_items = learn.dls.valid.items[:,0]\nDs_items     = learn.dls.valid.items[:,1]\nds_in_labels = learn.dls.valid.items[:,:2] \nu_a=np.unique(alphas_items,)\nu_D=np.unique(Ds_items,)\n\nalphas_idx = [np.flatnonzero(alphas_items==a) for a in u_a]\nDs_idx     = [np.flatnonzero(Ds_items==D)     for D in u_D]\n\nintersect_idx = np.array([[reduce(partial(np.intersect1d,assume_unique=True),\n                                  (alphas_idx[i],Ds_idx[j]))\n                           for j,D in enumerate(u_D)]\n                          for i,a in enumerate(u_a)], dtype=object)\n\nalphas_idx_flat = [item for sublist in alphas_idx for item in sublist]\nDs_idx_flat     = [item for sublist in Ds_idx     for item in sublist]\n\npred, mu, logvar, c = preds\n\nprint(ds_in.shape, learn.dls.valid.items.shape)\nprint(L(map(len, alphas_idx)), len(alphas_idx_flat), L(map(len, Ds_idx)), len(Ds_idx_flat))\n\n\nassert not np.any( np.array(L(map(len, alphas_idx))) &lt; trajs_per_aD ), 'There are not enough trajectories to sample from. Increase N when loading.'\n\n\nassert c.shape[-1]&gt;(T_gen+model.receptive_field), 'Has the long mode been activated?'\n\nWe sample from the model and save it for each parameter combination.\n\nfor a_idx,a in enumerate(ds_args[\"alpha\"]):\n    for D_idx,D in enumerate(ds_args[\"D\"]):\n        fname = \"../../data/gen/\"+model_name+f'_disp_gen_a{a:.3g}D{D:.3g}'.replace('.','')+'.npz'\n        if not os.path.exists(fname):\n            os.makedirs('../../data/gen/', exist_ok=True)\n            indices = (a_idx,D_idx)\n            disp_gen, logits = learn.model.sample_batch(total_samples, bs=bs,\n                                                        c=c[intersect_idx[indices][:trajs_per_aD]].repeat(samples_per_c,1,1),\n                                                        T=T_gen\n                                                       )\n            disp_gen = disp_gen.squeeze().detach().cpu().numpy()\n            np.savez_compressed(fname, disp_gen=disp_gen)\n            print(\"Saved at:\", fname)\n            print(\"with dimensions\", disp_gen.shape)\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a168D0001.npz\nwith dimensions (6000, 6000)\n\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a172D0001.npz\nwith dimensions (6000, 6000)\n\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a176D0001.npz\nwith dimensions (6000, 6000)\n\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a18D0001.npz\nwith dimensions (6000, 6000)\n\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a184D0001.npz\nwith dimensions (6000, 6000)\n\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a188D0001.npz\nwith dimensions (6000, 6000)\n\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a192D0001.npz\nwith dimensions (6000, 6000)\n\n\n\n\n\nSaved at: ../../data/gen/fbm_E144_disp_gen_a196D0001.npz\nwith dimensions (6000, 6000)",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#load-displacements",
    "href": "tutorials/generation_fbm.html#load-displacements",
    "title": "Generation of FBM",
    "section": "Load displacements",
    "text": "Load displacements\nOnce the displacements are generated and saved, we load them to analyze the correlations and the TA-MSD.\n\nprint('D:', ds_args[\"D\"])\nprint('a:', ds_args[\"alpha\"])\n\nD: [0.001]\na: [0.04 0.08 0.12 0.16 0.2  0.24 0.28 0.32 0.36 0.4  0.44 0.48 0.52 0.56\n 0.6  0.64 0.68 0.72 0.76 0.8  0.84 0.88 0.92 0.96 1.   1.04 1.08 1.12\n 1.16 1.2  1.24 1.28 1.32 1.36 1.4  1.44 1.48 1.52 1.56 1.6  1.64 1.68\n 1.72 1.76 1.8  1.84 1.88 1.92 1.96]\n\n\n\ndisp_gen_6k = {f'{a:.3g}'+f',{D:.3g}':[] for D in ds_args[\"D\"] for a in ds_args[\"alpha\"]}\n\n\nfor a in ds_args[\"alpha\"]:\n    for D in ds_args[\"D\"]:\n        fname = \"../../data/gen/\"+model_name+f'_disp_gen_a{a:.3g}D{D:.3g}'.replace('.','')+'.npz'\n        with np.load(fname, allow_pickle=True) as f:\n            k = f'{a:.3g}'+f',{D:.3g}'\n            disp_gen_6k[k] = f['disp_gen']",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#correlations-1",
    "href": "tutorials/generation_fbm.html#correlations-1",
    "title": "Generation of FBM",
    "section": "Correlations",
    "text": "Correlations\nWe compute the correlations of the generated displacements as we did before.\n\ndisp_corr_6k = {f'{a:.3g}'+f',{D:.3g}':[] for D in ds_args[\"D\"] for a in ds_args[\"alpha\"]}\n\n\nwindows = 420\ndelta_t = np.arange(1,windows)\nlog_delta_t = np.log(delta_t)\nfor a in ds_args[\"alpha\"][[12,36,48]]:\n    for D in ds_args[\"D\"]:\n        k = f'{a:.3g}'+f',{D:.3g}'\n        disp_corr_6k[k] = correlations(disp_gen_6k[k], windows)\n\n\nfor a,D in zip(ds_args[\"alpha\"][[12,36,48]],[1e-3]*3):\n    k = f'{a:.3g}'+f',{D:.3g}'\n    plt.loglog(delta_t, np.abs(disp_corr_6k[k]/disp_corr_6k[k][:1]).T, label=f'{a:.3g}');\nplt.xlabel(r'$\\Delta t$');\nplt.axvline(learn.model.receptive_field, ls='--', lw=0.2,c='k');\nplt.ylabel(\"Normalized Absolute Mean\\nof products\" \n           r\" $\\left|\\langle \\Delta x_t\\Delta x_{t+\\Delta t} \\rangle\\right|/\\Delta x_0}^2$\");\nplt.legend(title=r'$\\alpha$');\n\n\n\n\n\n\n\n\nThe correlation curves for different exponents \\(\\alpha\\) are straight until the time lag \\(\\Delta t\\) corresponding to the receptive field where they start to vanish.",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#ta-msd-1",
    "href": "tutorials/generation_fbm.html#ta-msd-1",
    "title": "Generation of FBM",
    "section": "TA-MSD",
    "text": "TA-MSD\nWe analyze the slope of the TA-MSD from the lengthy generated trajectories.\n\ntamsd_6k = {f'{a:.3g}'+f',{D:.3g}':[] for D in ds_args[\"D\"] for a in ds_args[\"alpha\"]}\n\n\ndelta_t = np.arange(1,windows)\nlog_delta_t = np.log(delta_t)\nfor a in ds_args[\"alpha\"]:\n    for D in ds_args[\"D\"]:\n        k = f'{a:.3g}'+f',{D:.3g}'\n        fname = \"../../data/analysis/\"+model_name+f'_tamsd_6k_{a:.3g}D{D:.3g}'.replace('.','')+'.npz'\n        if not os.path.exists(fname): # create and save\n            os.makedirs('../../data/analysis/', exist_ok=True)\n            tamsd_6k[k] = TAMSD(np.cumsum(disp_gen_6k[k],axis=-1),delta_t)\n            np.savez_compressed(fname, tamsd=tamsd_6k[k])\n            print(\"Saved at:\", fname)\n            print(\"with dimensions\", tamsd_6k[k].shape)\n        else: # load\n            with np.load(fname, allow_pickle=True) as f:\n            tamsd_6k[k] = f['tamsd']\n\nWe observe the slope remains almost constant up to the time lag corresponding to the receptive field. From there, the curve goes to 1 meaning that correlations are not well reproduced further than the receptive field.\n\nlog_delta_t = np.log(delta_t)\nmoving_win = 2\nfor i,a in enumerate(ds_args[\"alpha\"][[0,4,14,24,34,44,48]]):\n    for D in ds_args[\"D\"]:\n        k = f'{a:.3g}'+f',{D:.3g}'\n    log_mean_a = np.log(tamsd_6k[k][:,:windows-1]).mean(0)\n    moving_slope_a = (log_mean_a[:-moving_win]-log_mean_a[moving_win:])/(log_delta_t[:-moving_win]-log_delta_t[moving_win:])\n    plt.plot(delta_t[moving_win//2:-moving_win//2], moving_slope_a, c=f'C{i}', label=f'{a:.3g}');\nplt.xlabel(r'$\\Delta t$');    plt.grid(); plt.ylim([0,2])\nplt.axvline(learn.model.receptive_field, c='k', lw=1,ls='--');\nplt.ylabel(\"TA-MSD moving slope\");\nplt.legend(title=r'$\\alpha$');",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/generation_fbm.html#get-alpha-exponent",
    "href": "tutorials/generation_fbm.html#get-alpha-exponent",
    "title": "Generation of FBM",
    "section": "Get \\(\\alpha\\) exponent",
    "text": "Get \\(\\alpha\\) exponent\nWe show the difference of taking the fitting before and after the receptive field (RF).\n\nk = f'{ds_args[\"alpha\"][0]}'+f',{ds_args[\"D\"][0]}'\nwindows = tamsd_6k[k].shape[-1]\ndelta_t = np.arange(1,windows)\nlog_delta_t = np.log(delta_t)\n# delta_ts &lt; RF:\nskip = 0\nperc = skip + max(4, 20)\n# delta_ts &gt; RF:\nskip_ = 380\nperc_ = 400\nexponents = {f'{a:.3g}'+f',{D:.3g}':[] for D in ds_args[\"D\"] for a in ds_args[\"alpha\"]}\nexponents_ = {f'{a:.3g}'+f',{D:.3g}':[] for D in ds_args[\"D\"] for a in ds_args[\"alpha\"]}\nfor j,D in enumerate(ds_args[\"D\"]):\n    for i,a in enumerate(ds_args[\"alpha\"]):\n        k = f'{a:.3g}'+f',{D:.3g}'\n        exponents[k]  = np.polyfit(log_delta_t[skip :perc ], np.log(tamsd_6k[k][:,skip :perc ]).T, deg=1)[0]\n        exponents_[k] = np.polyfit(log_delta_t[skip_:perc_], np.log(tamsd_6k[k][:,skip_:perc_]).T, deg=1)[0]\n\n\nZ_a_r  = np.empty((len(ds_args[\"alpha\"]), len(ds_args['D']),exponents[k].shape[0]))\nZ_a_r_ = np.empty((len(ds_args[\"alpha\"]), len(ds_args['D']),exponents_[k].shape[0]))\nfor j,D in enumerate(ds_args[\"D\"]):\n    for i,a in enumerate(ds_args[\"alpha\"]):\n        k = f'{a:.3g}'+f',{D:.3g}'\n        Z_a_r[i,j]  = exponents[k]\n        Z_a_r_[i,j] = exponents_[k]\n\n\ntraj_per_comb = exponents[k].shape[0]\n\nFor time lags smaller than the receptive field, the estimated exponent \\(\\alpha_g\\) is very close to the ground truth \\(\\alpha\\). However, for bigger time lags the estimated exponent remains close to \\(\\alpha=1\\) (Brownian motion) meaning the displacements are more uncorrelated.\n\nfig, axs = plt.subplots(2,1, figsize=(7,14), sharex=True, gridspec_kw=dict(hspace=0.1))\nfor j,D in enumerate(ds_args[\"D\"]):\n    x_flat = np.repeat(ds_args[\"alpha\"],traj_per_comb).reshape(-1)\n    bins = np.round(np.concatenate(([0],\n                                    ds_args[\"alpha\"][1:]-(ds_args[\"alpha\"][1:]-ds_args[\"alpha\"][:-1])*.5,\n                                    [2.])),\n                    2)\n    cmaps = ['Blues', 'Oranges']\n    for i, y in enumerate([Z_a_r[:,j],Z_a_r_[:,j]]):\n        y_flat = y.reshape(-1)\n        axs[i].hist2d(x_flat,y_flat,bins=(bins,250),cmin=2,\n                  norm=matplotlib.colors.LogNorm(), cmap=cmaps[i],\n                  );\n        axs[i].plot([0,1,2], 'gray', alpha=0.7);\n        axs[i].plot(ds_args[\"alpha\"], y.mean(-1),'k', alpha=0.8,label='mean');\n\nfor ax in axs:\n    ax.grid(); ax.set_ylim([0,2]); ax.set_xlim([0,2])\n    ax.locator_params(nbins=3); ax.set_ylabel(r\"$\\alpha_g$\", rotation=0);\n    ax.set_xlabel(r'$\\alpha$');    \naxs[0].set_title(r'$\\Delta t&lt;$RF');\naxs[1].set_title(r'$\\Delta t&gt;$RF');",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Generation of FBM"
    ]
  },
  {
    "objectID": "tutorials/training_fbm.html",
    "href": "tutorials/training_fbm.html",
    "title": "Model training on FBM",
    "section": "",
    "text": "In this tutorial, we aim at training SPIVAE with the dataset of fractional Brownian motion (FBM) to extract the generalized diffusion coefficient \\(D\\), and the anomalous exponent \\(\\alpha\\).\n\nParameters\nTo train the models, we use the fastai library that provides easy to use methods. First, we gather everything needed to train (the data, the model, the loss, the optimizer, etc.) into a Learner object. We will use the Learner to hold all the parameters and handle the training procedure.\nWe start selecting the parameters of the device to train on, the dataset, and the model.\n\nDEVICE= 'cpu'  # 'cuda'\nprint(DEVICE)\n\ncpu\n\n\nTo construct the dataset of FBM, we vary \\(D\\) logarithmically inside the range \\(10^{-5}\\) and \\(10^{-2}\\) such that the displacements are smaller than one. At the same time, we choose \\(\\alpha\\in[0.2, 1.8]\\). We take the same amount of trajectories for each combination of parameters, about 100 thousand trajectories in total. We split them in training and validation sets, and select a batch size bs.\n\nDs = np.geomspace(1e-5,1e-2, 10) \nalphas = np.linspace(0.2,1.8,21)\nn_alphas, n_Ds = len(alphas), len(Ds)\nds_args = dict(path=\"../../data/raw/\", model='fbm', # 'sbm'\n               N=int(100_000/n_alphas/n_Ds), T=400,\n               D=Ds, alpha=alphas,\n               N_save=6_000, T_save=400,\n               seed=0, valid_pct=0.2, bs=2**8,)\n\nWe generate training data as explained in the data docs. You can skip this step if you already generated data using the data generation notebook.\n\ndataset = AD.create_dataset(T=ds_args[\"T\"], N_models=ds_args[\"N\"],\n                            exponents=ds_args[\"alpha\"],\n                            dimension=1, models=[2],  # fbm\n                            t_save=ds_args[\"T_save\"], N_save=ds_args[\"N_save\"],\n                            save_trajectories=True, path=\"../../data/raw/\")\n\nWe create the data loaders dls for training and validation with the parameters we selected above.\n\ndls = load_data(ds_args).to(DEVICE)\ndls[1].drop_last = True # for validation to throw the last incomplete batch or not\ndls[0].drop_last, dls[1].drop_last, dls[1].bs, dls.device\n\n(True, True, 256, 'cpu')\n\n\nWe set a small model to train rapidly, but large enough to provide adequate expressiveness. We fix 6 latent neurons, as a priori, we do not know how many neurons will encode the trajectory parameters.\n\nmodel_args = dict(# VAE #################\n                  o_dim=ds_args['T']-1,\n                  nc_in=1,  # 1D\n                  nc_out=6, # = z_dim\n                  nf=[16]*4,\n                  avg_size=16,\n                  encoder=[200,100],\n                  z_dim=6,  # latent dimension\n                  decoder=[100,200],\n                  beta=0,\n                  # WaveNet ############\n                  in_channels=1,\n                  res_channels=16,skip_channels=16,\n                  c_channels=6, # = nc_out\n                  g_channels=0,\n                  res_kernel_size=3,\n                  layer_size=4,  # 6  # Largest dilation is 2**layer_size\n                  stack_size=1,\n                  out_distribution= \"Normal\",\n                  num_mixtures=1,\n                  use_pad=False,    \n                  model_name = 'SPIVAE',\n                 )\n\nWe initialize a model and define its loss function as defined in Utils. The initial loss for this dataset is around 1.5, bigger than that the initialization provides an unstable model that may not train properly.\n\nmodel = VAEWaveNet(**model_args).to(DEVICE)\nprint('RF:', model.receptive_field, 'bs:', dls.bs)\nx,y=b = dls.one_batch(); t = model(x)\nloss_fn = Loss(model.receptive_field, model.c_channels, \n                    beta=model_args['beta'], reduction='mean')\nl = loss_fn(t,y).item(); \nprint('Initial loss: ',l)\nassert l&lt;1.5, 'Initial loss should be around 1.5 or less'\n\nRF: 32 bs: 256\nInitial loss:  0.9262354373931885\n\n\nWe now set a few callback functions to show relevant information during training. The first two update a plot of the total loss for training and validation, and the Kullback-Leibler divergence (\\(D_{KL}\\)) of the latent neurons, respectively. The other two record the reconstruction loss and the \\(D_{KL}\\) of each latent neuron.\n\ncallbacks = [ShowLossCallback(), ShowKLDsCallback(),\n             GMsCallback(model.receptive_field,model.c_channels),\n             KLDsCallback(model.c_channels)]\n\nWe add two metrics to follow the reconstruction loss and the divergence term during training.\n\nmetrics = [GaussianMixtureMetric(model.receptive_field, model.c_channels,reduction='mean'),\n           KLDMetric(model.c_channels,),\n          ]\n\nWith all the ingredients, we create the Learner with the default optimizer, Adam.\n\nlearn = Learner(dls, model, loss_func=loss_fn, opt_func=Adam, cbs=callbacks, metrics=metrics,)\nif torch.cuda.is_available() and DEVICE=='cuda': learn.model.cuda()\n\nThe learner can show us a summary including the model sizes and number of parameters.\n\nlearn.summary()\n\n\n\n\n\n\n\n\nVAEWaveNet (Input shape: 256 x 1 x 399)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     256 x 16 x 397      \nConv1d                                    64         True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 395      \nConv1d                                    784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 393      \nConv1d                                    784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 391      \nConv1d                                    784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 16       \nAdaptiveAvgPool1d                                              \nAdaptiveMaxPool1d                                              \n____________________________________________________________________________\n                     256 x 512           \nView                                                           \n____________________________________________________________________________\n                     256 x 200           \nLinear                                    102600     True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 100           \nLinear                                    20100      True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 12            \nLinear                                    1212       True      \n____________________________________________________________________________\n                     256 x 100           \nLinear                                    700        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 200           \nLinear                                    20200      True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 512           \nLinear                                    102912     True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 32       \nView                                                           \n____________________________________________________________________________\n                     256 x 16 x 393      \nConvTranspose1d                           784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 395      \nConvTranspose1d                           784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 397      \nConvTranspose1d                           784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 6 x 399       \nConvTranspose1d                           294        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 399      \nConv1d                                    32         True      \n____________________________________________________________________________\n                     256 x 16 x 397      \nConv1d                                    528        True      \n____________________________________________________________________________\n                     256 x 32 x 395      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \n____________________________________________________________________________\n                     256 x 32 x 391      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \n____________________________________________________________________________\n                     256 x 32 x 383      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \n____________________________________________________________________________\n                     256 x 32 x 367      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \nReLU                                                           \nConv1d                                    272        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 3 x 367       \nConv1d                                    51         True      \n____________________________________________________________________________\n\nTotal params: 262,885\nTotal trainable params: 262,885\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam&gt;\nLoss function: &lt;SPIVAE.utils.Loss object&gt;\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - Recorder\n  - ProgressCallback\n  - ShowLossCallback\n  - GMsCallback\n  - ShowKLDsCallback\n  - KLDsCallback\n\n\nFinally, we need a learning rate. Conveniently, fastai includes a learning rate finder. This finder can suggest some points, each based on a criterion that guides us. Hence, we try with one order above and below the default criterion, the valley.\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=9.120108734350652e-05)\n\n\n\n\n\n\n\n\n\nThe valley is around \\(10^{-4}\\), thus we will start trying a learning rate of \\(10^{-3}\\) to see if we can learn fast.\nDuring the search, not only the loss was logged but also the \\(D_{KL}\\) which we can see here:\n\nplt.semilogy(np.stack(learn.kl_ds.preds)); learn.kl_ds.preds=[]\n\n\n\n\n\n\n\n\nDuring the training, we will keep an eye on both the total loss and the \\(D_{KL}\\).\n\n\nTraining with \\(\\beta\\)=0\nWe start training with \\(\\beta=0\\) to have no additional constraint in the latent neurons and allow the VAE to use the full capacity of its bottleneck.\n\nlearn.loss_func.beta=0\n\nTo ease the training, we update the model’s parameters following the learning rate schedule developed by Leslie N. Smith et al. (2017) and already implemented in fastai. We choose as the maximum learning rate the one derived from the finder above.\n\nlearn.fit_one_cycle(64, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-1.315952\n-1.661407\n-1.661407\n19.406342\n01:09\n\n\n1\n-2.112537\n-2.151353\n-2.151353\n64.277298\n01:10\n\n\n2\n-2.239122\n-2.249071\n-2.249071\n86.196838\n01:11\n\n\n3\n-2.244182\n-2.256283\n-2.256283\n78.044266\n01:10\n\n\n4\n-2.238847\n-2.265728\n-2.265728\n79.355087\n01:10\n\n\n5\n-2.185477\n-2.220979\n-2.220979\n73.193192\n01:11\n\n\n6\n-2.157342\n-2.245884\n-2.245884\n68.523232\n01:11\n\n\n7\n-2.011828\n-2.076498\n-2.076498\n48.271271\n01:10\n\n\n8\n-2.026002\n-2.205460\n-2.205460\n14.866062\n01:10\n\n\n9\n-2.146519\n-2.218804\n-2.218804\n27.197741\n01:12\n\n\n10\n-2.164488\n-2.268744\n-2.268744\n53.392033\n01:11\n\n\n11\n-2.094013\n-2.184355\n-2.184355\n72.369965\n01:10\n\n\n12\n-2.228285\n-2.122396\n-2.122396\n162.265594\n01:10\n\n\n13\n-2.266493\n-2.289713\n-2.289713\n189.916687\n01:10\n\n\n14\n-2.229059\n-1.878625\n-1.878625\n314.366608\n01:11\n\n\n15\n-2.244426\n-2.255815\n-2.255815\n336.166351\n01:10\n\n\n16\n-2.272467\n-2.274356\n-2.274356\n377.487793\n01:11\n\n\n17\n-2.277053\n-2.275987\n-2.275987\n417.207703\n01:10\n\n\n18\n-2.269186\n-2.246015\n-2.246015\n479.375000\n01:11\n\n\n19\n-2.293643\n-2.303562\n-2.303562\n493.494781\n01:10\n\n\n20\n-2.299952\n-2.314991\n-2.314991\n547.708008\n01:10\n\n\n21\n-2.322182\n-2.281061\n-2.281061\n568.945740\n01:10\n\n\n22\n-2.310960\n-2.320824\n-2.320824\n608.434265\n01:10\n\n\n23\n-2.315642\n-2.324992\n-2.324992\n607.956360\n01:11\n\n\n24\n-2.332518\n-2.312339\n-2.312339\n635.526489\n01:11\n\n\n25\n-2.317588\n-2.331322\n-2.331322\n659.979919\n01:10\n\n\n26\n-2.326688\n-2.328422\n-2.328422\n651.702820\n01:11\n\n\n27\n-2.339881\n-2.334195\n-2.334195\n681.555664\n01:11\n\n\n28\n-2.329673\n-2.333597\n-2.333597\n717.498901\n01:10\n\n\n29\n-2.340475\n-2.333066\n-2.333066\n720.397827\n01:10\n\n\n30\n-2.338010\n-2.337913\n-2.337913\n755.900269\n01:11\n\n\n31\n-2.332206\n-2.332510\n-2.332510\n756.721130\n01:12\n\n\n32\n-2.351339\n-2.338526\n-2.338526\n782.172852\n01:11\n\n\n33\n-2.340485\n-2.338783\n-2.338783\n805.748047\n01:11\n\n\n34\n-2.340624\n-2.342476\n-2.342476\n810.832153\n01:13\n\n\n35\n-2.343892\n-2.342334\n-2.342334\n830.463257\n01:11\n\n\n36\n-2.348852\n-2.345546\n-2.345546\n821.223083\n01:11\n\n\n37\n-2.355019\n-2.345020\n-2.345020\n839.597351\n01:11\n\n\n38\n-2.345042\n-2.346593\n-2.346593\n839.534668\n01:11\n\n\n39\n-2.355663\n-2.346778\n-2.346778\n839.826233\n01:12\n\n\n40\n-2.342772\n-2.347796\n-2.347796\n840.443481\n01:11\n\n\n41\n-2.358884\n-2.348896\n-2.348896\n830.699219\n01:11\n\n\n42\n-2.349423\n-2.349129\n-2.349129\n840.666992\n01:11\n\n\n43\n-2.348464\n-2.346027\n-2.346027\n832.678467\n01:12\n\n\n44\n-2.352715\n-2.349886\n-2.349886\n834.427307\n01:11\n\n\n45\n-2.344991\n-2.349920\n-2.349920\n826.926025\n01:11\n\n\n46\n-2.341416\n-2.350274\n-2.350274\n831.225464\n01:11\n\n\n47\n-2.350832\n-2.350190\n-2.350190\n828.069336\n01:12\n\n\n48\n-2.345083\n-2.350618\n-2.350618\n826.633118\n01:12\n\n\n49\n-2.360827\n-2.350861\n-2.350861\n821.838623\n01:11\n\n\n50\n-2.352463\n-2.350962\n-2.350962\n830.453674\n01:12\n\n\n51\n-2.347570\n-2.351095\n-2.351095\n823.741089\n01:12\n\n\n52\n-2.360364\n-2.351196\n-2.351196\n821.325806\n01:12\n\n\n53\n-2.343230\n-2.351074\n-2.351074\n823.521729\n01:11\n\n\n54\n-2.355769\n-2.351494\n-2.351494\n821.793335\n01:12\n\n\n55\n-2.358197\n-2.351494\n-2.351494\n817.322815\n01:12\n\n\n56\n-2.359900\n-2.351530\n-2.351530\n815.922485\n01:12\n\n\n57\n-2.349110\n-2.351698\n-2.351698\n814.793518\n01:11\n\n\n58\n-2.355841\n-2.351716\n-2.351716\n815.463562\n01:11\n\n\n59\n-2.358056\n-2.351770\n-2.351770\n813.260559\n01:15\n\n\n60\n-2.354583\n-2.351813\n-2.351813\n811.844543\n01:12\n\n\n61\n-2.344743\n-2.351826\n-2.351826\n812.462219\n01:13\n\n\n62\n-2.350585\n-2.351825\n-2.351825\n812.875671\n01:12\n\n\n63\n-2.355194\n-2.351831\n-2.351831\n812.403564\n01:12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter training, we see a validation loss around -2.35 and two neurons that contribute the most to the \\(D_{KL}\\). We take a checkpoint of the model at this moment.\n\nE=64; model_name = 'fbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/fbm_E64.tar\n\n\n\nplt.semilogy(np.stack(learn.kl_ds.preds));\n\n\n\n\n\n\n\n\n\n\nAnnealing \\(\\beta\\)\nNow, we increase \\(\\beta\\) to impose a Gaussian prior into the latent neurons distribution which effectively forces the encoding of the already present information to use the minimal number of neurons while noising out the rest of neurons.\n\nE=64\nmodel_name = 'fbm' + f'_E{E}'\nc_point, model = load_checkpoint(\"./models/\"+model_name,device=DEVICE)\n\nLoading checkpoint: ./models/fbm_E64.tar\non device: cpu\n\n\n\nlearn.loss_func.beta=1e-4; model_args.update(dict(beta=1e-4))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.324830\n-2.338405\n-2.349152\n107.466675\n01:09\n\n\n1\n-2.338842\n-2.340303\n-2.345047\n47.436031\n01:10\n\n\n2\n-2.339993\n-2.337490\n-2.341151\n36.604542\n01:10\n\n\n3\n-2.337698\n-2.346305\n-2.349505\n32.004436\n01:10\n\n\n4\n-2.342737\n-2.319283\n-2.322044\n27.611586\n01:10\n\n\n5\n-2.343880\n-2.324024\n-2.326623\n25.985027\n01:10\n\n\n6\n-2.344337\n-2.348159\n-2.350667\n25.081089\n01:10\n\n\n7\n-2.343842\n-2.349709\n-2.352086\n23.770494\n01:11\n\n\n8\n-2.345186\n-2.352701\n-2.355143\n24.418821\n01:10\n\n\n9\n-2.355095\n-2.356360\n-2.358828\n24.684273\n01:09\n\n\n10\n-2.358190\n-2.361038\n-2.363501\n24.632402\n01:11\n\n\n11\n-2.362531\n-2.362979\n-2.365445\n24.661421\n01:11\n\n\n12\n-2.357859\n-2.363399\n-2.365850\n24.508953\n01:10\n\n\n13\n-2.358759\n-2.363714\n-2.366147\n24.336988\n01:10\n\n\n14\n-2.360825\n-2.363775\n-2.366217\n24.420610\n01:10\n\n\n15\n-2.355404\n-2.363865\n-2.366307\n24.411386\n01:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe save the model after each cycle, just in case all the neurons collapse due to a big \\(\\beta\\).\n\nE=64+16; model_name = 'fbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/fbm_E80.tar\n\n\nThen, we increase the \\(\\beta\\) and train again.\n\nlearn.loss_func.beta=6e-4; model_args.update(dict(beta=6e-4))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.353231\n-2.353524\n-2.364641\n18.528250\n01:09\n\n\n1\n-2.348532\n-2.352497\n-2.362990\n17.487579\n01:10\n\n\n2\n-2.342875\n-2.334392\n-2.344330\n16.562178\n01:11\n\n\n3\n-2.346903\n-2.336486\n-2.345794\n15.511265\n01:10\n\n\n4\n-2.330870\n-2.346205\n-2.356031\n16.375021\n01:10\n\n\n5\n-2.349575\n-2.353170\n-2.362580\n15.683105\n01:10\n\n\n6\n-2.347398\n-2.351249\n-2.360387\n15.228333\n01:11\n\n\n7\n-2.345601\n-2.350861\n-2.359752\n14.819258\n01:10\n\n\n8\n-2.352276\n-2.356376\n-2.364991\n14.358064\n01:10\n\n\n9\n-2.356200\n-2.355854\n-2.364318\n14.105173\n01:10\n\n\n10\n-2.350616\n-2.355227\n-2.363599\n13.954180\n01:12\n\n\n11\n-2.355976\n-2.357581\n-2.365860\n13.798420\n01:10\n\n\n12\n-2.354166\n-2.357984\n-2.366087\n13.504392\n01:10\n\n\n13\n-2.359440\n-2.358157\n-2.366241\n13.472176\n01:10\n\n\n14\n-2.343340\n-2.358246\n-2.366287\n13.400112\n01:10\n\n\n15\n-2.365923\n-2.358313\n-2.366364\n13.418869\n01:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE=64+16*2; model_name = 'fbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/fbm_E96.tar\n\n\nWe keep training to noise out the collapsed neurons while maintaining good reconstruction loss mix_gaussian_loss.\n\nlearn.loss_func.beta=1e-3; model_args.update(dict(beta=1e-3))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.348945\n-2.353240\n-2.364978\n11.738488\n01:10\n\n\n1\n-2.358876\n-2.342992\n-2.353953\n10.961354\n01:10\n\n\n2\n-2.350276\n-2.350280\n-2.360747\n10.466887\n01:11\n\n\n3\n-2.341486\n-2.282615\n-2.292582\n9.966481\n01:11\n\n\n4\n-2.342745\n-2.343670\n-2.353052\n9.381420\n01:10\n\n\n5\n-2.345502\n-2.333569\n-2.343357\n9.788860\n01:10\n\n\n6\n-2.361416\n-2.354589\n-2.363912\n9.322714\n01:10\n\n\n7\n-2.350763\n-2.352047\n-2.361214\n9.165956\n01:11\n\n\n8\n-2.354032\n-2.354136\n-2.363111\n8.974744\n01:10\n\n\n9\n-2.351079\n-2.355446\n-2.364451\n9.005571\n01:10\n\n\n10\n-2.348526\n-2.355358\n-2.364368\n9.010308\n01:10\n\n\n11\n-2.349510\n-2.355702\n-2.364724\n9.022109\n01:10\n\n\n12\n-2.359064\n-2.356081\n-2.365134\n9.052643\n01:10\n\n\n13\n-2.358692\n-2.356183\n-2.365181\n8.999000\n01:10\n\n\n14\n-2.357382\n-2.356289\n-2.365324\n9.035031\n01:10\n\n\n15\n-2.347834\n-2.356310\n-2.365310\n9.001582\n01:11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE=64+16*3; model_name = 'fbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/fbm_E112.tar\n\n\n\nlearn.loss_func.beta=2e-3; model_args.update(dict(beta=2e-3))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.350208\n-2.348301\n-2.362810\n7.254685\n01:10\n\n\n1\n-2.337677\n-2.346455\n-2.359850\n6.697080\n01:11\n\n\n2\n-2.345940\n-2.336791\n-2.349714\n6.461686\n01:11\n\n\n3\n-2.339710\n-2.338348\n-2.351251\n6.451570\n01:10\n\n\n4\n-2.344926\n-2.340880\n-2.353410\n6.265362\n01:11\n\n\n5\n-2.349301\n-2.347707\n-2.359997\n6.144722\n01:11\n\n\n6\n-2.336591\n-2.344263\n-2.356583\n6.159823\n01:10\n\n\n7\n-2.345398\n-2.346607\n-2.358751\n6.072074\n01:10\n\n\n8\n-2.342644\n-2.346272\n-2.358593\n6.160376\n01:10\n\n\n9\n-2.345847\n-2.348051\n-2.360079\n6.013485\n01:11\n\n\n10\n-2.351193\n-2.349379\n-2.361663\n6.141795\n01:10\n\n\n11\n-2.350389\n-2.349450\n-2.361586\n6.067914\n01:10\n\n\n12\n-2.351185\n-2.349608\n-2.361853\n6.122767\n01:10\n\n\n13\n-2.344490\n-2.349607\n-2.361763\n6.078405\n01:10\n\n\n14\n-2.347708\n-2.349838\n-2.362053\n6.107482\n01:11\n\n\n15\n-2.342868\n-2.349836\n-2.362056\n6.109914\n01:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE=64+16*4; model_name = 'fbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/fbm_E128.tar\n\n\n\nlearn.loss_func.beta=4e-3; model_args.update(dict(beta=4e-3))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.344279\n-2.338168\n-2.358795\n5.156413\n01:10\n\n\n1\n-2.345974\n-2.335615\n-2.355980\n5.091214\n01:14\n\n\n2\n-2.328641\n-2.337625\n-2.357382\n4.939382\n01:11\n\n\n3\n-2.320290\n-2.328844\n-2.348158\n4.828393\n01:11\n\n\n4\n-2.326955\n-2.337008\n-2.356167\n4.790024\n01:11\n\n\n5\n-2.326622\n-2.334390\n-2.353814\n4.856228\n01:10\n\n\n6\n-2.328627\n-2.337150\n-2.356401\n4.812714\n01:11\n\n\n7\n-2.324614\n-2.339001\n-2.358472\n4.867772\n01:11\n\n\n8\n-2.321634\n-2.339200\n-2.358446\n4.811536\n01:10\n\n\n9\n-2.346042\n-2.339435\n-2.358616\n4.795233\n01:10\n\n\n10\n-2.342316\n-2.339132\n-2.358153\n4.755326\n01:11\n\n\n11\n-2.333755\n-2.339544\n-2.358423\n4.719747\n01:10\n\n\n12\n-2.331389\n-2.339730\n-2.358924\n4.798558\n01:10\n\n\n13\n-2.339941\n-2.339780\n-2.358954\n4.793717\n01:11\n\n\n14\n-2.335042\n-2.339912\n-2.359108\n4.799071\n01:11\n\n\n15\n-2.337263\n-2.339907\n-2.359071\n4.790753\n01:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE=64+16*5; model_name = 'fbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/fbm_E144.tar\n\n\nAfter training, we observe a good reconstruction loss around -2.36, while the \\(D_{KL}\\) is on the order of one for two neurons and the rest are three orders of magnitude below. We say that two neurons survive while the rest are noised out. We will see in the analysis tutorial how these two neurons encode the minimal relevant information to generate the trajectories.",
    "crumbs": [
      "Tutorials",
      "Fractional Brownian motion",
      "Model training on FBM"
    ]
  },
  {
    "objectID": "tutorials/training_sbm.html",
    "href": "tutorials/training_sbm.html",
    "title": "Model training on SBM",
    "section": "",
    "text": "In this tutorial, we aim at training SPIVAE with the dataset of scaled Brownian motion (SBM) to extract the aging diffusion coefficient \\(D(t)\\), and the anomalous exponent \\(\\alpha\\).\n\nParameters\nTo train the models, we use the fastai library that provides easy to use methods. First, we gather everything needed to train (the data, the model, the loss, the optimizer, etc.) into a Learner object. We will use the Learner to hold all the parameters and handle the training procedure.\nWe start selecting the parameters of the device to train on, the dataset, and the model.\n\nDEVICE= 'cpu'  # 'cuda'\nprint(DEVICE)\n\ncpu\n\n\nTo construct the dataset of SBM, we vary \\(D_0\\) logarithmically inside the range \\(10^{-5}\\) and \\(10^{-2}\\) such that the displacements are not much bigger than one. At the same time, we choose \\(\\alpha\\in[0.2, 1.8]\\). We take the same amount of trajectories for each combination of parameters, about 100 thousand trajectories in total. We split them in training and validation sets, and select a batch size (bs).\n\nDs = np.geomspace(1e-5,1e-2, 10) \nalphas = np.linspace(0.2,1.8,21)\nn_alphas, n_Ds = len(alphas), len(Ds)\nds_args = dict(path=\"../../data/raw/\", model='sbm',\n               N=int(100_000/n_alphas/n_Ds), T=400,\n               D=Ds, alpha=alphas,\n               N_save=1_000, T_save=400,\n               seed=0, valid_pct=0.2, bs=2**8,)\n\nWe generate training data as explained in the data docs. You can skip this step if you already generated data using the data generation notebook.\n\nfname = ds_args[\"path\"] + 'sbm.npz'\ndisp_gen = {f'{a:.3g}'+f',{D:.3g}':[] for D in ds_args[\"D\"] for a in ds_args[\"alpha\"]}\nif not os.path.exists(fname):  # create\n    for i,a in enumerate(ds_args[\"alpha\"]):\n        for j,D in enumerate(ds_args[\"D\"]):\n            k = f'{a:.3g}'+f',{D:.3g}'\n            disp_gen[k]=np.array([np.concatenate(([a,D],sbm(ds_args[\"T_save\"], a, sigma = D2sig(D)))) \n                                  for n in range(ds_args[\"N_save\"])]) # N, T+2\n    np.savez_compressed(fname,**disp_gen)\n    print('Saved at:', fname)\nelse:    print(f\"{fname} already exists. Load it with load_data().\")\n\nWe create the data loaders dls for training and validation with the parameters we selected above.\n\ndls = load_data(ds_args).to(DEVICE)\ndls[1].drop_last = True # for validation to throw the last incomplete batch or not\ndls[0].drop_last, dls[1].drop_last, dls[1].bs, dls.device\n\n(True, True, 256, 'cpu')\n\n\nWe set a small model to train rapidly, but large enough to provide adequate expressiveness. We fix 6 latent neurons, as a priori, we do not know how many neurons will encode the trajectory parameters.\n\nmodel_args = dict(# VAE #################\n                  o_dim=ds_args['T']-1,\n                  nc_in=1,  # 1D\n                  nc_out=6, # = z_dim\n                  nf=[16]*4,\n                  avg_size=16,\n                  encoder=[200,100],\n                  z_dim=6,  # latent dimension\n                  decoder=[100,200],\n                  beta=0,\n                  # WaveNet ############\n                  in_channels=1,\n                  res_channels=16,skip_channels=16,\n                  c_channels=6, # = nc_out\n                  g_channels=0,\n                  res_kernel_size=3,\n                  layer_size=4,  # 6  # Largest dilation is 2**layer_size\n                  stack_size=1,\n                  out_distribution= \"Normal\",\n                  num_mixtures=1,\n                  use_pad=False,    \n                  model_name = 'SPIVAE',\n                 )\n\nWe initialize a model and define its loss function as defined in Utils. The initial loss for this dataset is around 1.5, bigger than that the initialization provides an unstable model that may not train properly.\n\nmodel = VAEWaveNet(**model_args).to(DEVICE)\nprint('RF:', model.receptive_field, 'bs:', dls.bs)\nx,y=b = dls.one_batch(); t = model(x)\nloss_fn = Loss(model.receptive_field, model.c_channels, \n                    beta=model_args['beta'], reduction='mean')\nl = loss_fn(t,y).item(); \nprint('Initial loss: ',l)\nassert l&lt;1.5, 'Initial loss should be around 1.5 or less'\n\nRF: 32 bs: 256\nInitial loss:  1.0185976028442383\n\n\nWe now set a few callback functions to show relevant information during training. The first two update a plot of the total loss for training and validation, and the Kullback-Leibler divergence (\\(D_{KL}\\)) of the latent neurons, respectively. The other two record the reconstruction loss and the \\(D_{KL}\\) of each latent neuron.\n\ncallbacks = [ShowLossCallback(), ShowKLDsCallback(),\n             GMsCallback(model.receptive_field,model.c_channels),\n             KLDsCallback(model.c_channels)]\n\nWe add two metrics to follow the reconstruction loss and the divergence term during training.\n\nmetrics = [GaussianMixtureMetric(model.receptive_field, model.c_channels,reduction='mean'),\n           KLDMetric(model.c_channels,),\n          ]\n\nWith all the ingredients, we create the Learner with the default optimizer, Adam.\n\nlearn = Learner(dls, model, loss_func=loss_fn, opt_func=Adam, cbs=callbacks, metrics=metrics,)\nif torch.cuda.is_available() and DEVICE=='cuda': learn.model.cuda()\n\nThe learner can show us a summary including the model sizes and number of parameters.\n\nlearn.summary()\n\n\n\n\n\n\n\n\nVAEWaveNet (Input shape: 256 x 1 x 399)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     256 x 16 x 397      \nConv1d                                    64         True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 395      \nConv1d                                    784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 393      \nConv1d                                    784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 391      \nConv1d                                    784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 16       \nAdaptiveAvgPool1d                                              \nAdaptiveMaxPool1d                                              \n____________________________________________________________________________\n                     256 x 512           \nView                                                           \n____________________________________________________________________________\n                     256 x 200           \nLinear                                    102600     True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 100           \nLinear                                    20100      True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 12            \nLinear                                    1212       True      \n____________________________________________________________________________\n                     256 x 100           \nLinear                                    700        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 200           \nLinear                                    20200      True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 512           \nLinear                                    102912     True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 32       \nView                                                           \n____________________________________________________________________________\n                     256 x 16 x 393      \nConvTranspose1d                           784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 395      \nConvTranspose1d                           784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 397      \nConvTranspose1d                           784        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 6 x 399       \nConvTranspose1d                           294        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 16 x 399      \nConv1d                                    32         True      \n____________________________________________________________________________\n                     256 x 16 x 397      \nConv1d                                    528        True      \n____________________________________________________________________________\n                     256 x 32 x 395      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \n____________________________________________________________________________\n                     256 x 32 x 391      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \n____________________________________________________________________________\n                     256 x 32 x 383      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \n____________________________________________________________________________\n                     256 x 32 x 367      \nConv1d                                    1568       True      \n____________________________________________________________________________\n                     256 x 32 x 399      \nConv1d                                    192        True      \nConv1d                                    272        True      \nConv1d                                    272        True      \nReLU                                                           \nConv1d                                    272        True      \nReLU                                                           \n____________________________________________________________________________\n                     256 x 3 x 367       \nConv1d                                    51         True      \n____________________________________________________________________________\n\nTotal params: 262,885\nTotal trainable params: 262,885\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam&gt;\nLoss function: &lt;SPIVAE.utils.Loss object&gt;\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - Recorder\n  - ProgressCallback\n  - ShowLossCallback\n  - ShowKLDsCallback\n  - GMsCallback\n  - KLDsCallback\n\n\nFinally, we need a learning rate. Conveniently, fastai includes a learning rate finder. This finder can suggest some points, each based on a criterion that guides us. Hence, we try with one order above and below the default criterion, the valley.\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0005754399462603033)\n\n\n\n\n\n\n\n\n\nThe valley is around \\(5\\cdot10^{-4}\\), thus we will start trying a learning rate of \\(10^{-3}\\) to see if we can learn fast.\nDuring the search, not only the loss was logged but also the \\(D_{KL}\\) which we can see here:\n\nplt.semilogy(np.stack(learn.kl_ds.preds)); learn.kl_ds.preds=[]\n\n\n\n\n\n\n\n\nDuring the training, we will keep an eye on both the total loss and the \\(D_{KL}\\).\n\n\nTraining with \\(\\beta\\)=0\nWe start training with \\(\\beta=0\\) to have no additional constraint in the latent neurons and allow the VAE to use the full capacity of its bottleneck.\n\nlearn.loss_func.beta=0\n\nTo ease the training, we update the model’s parameters following the learning rate schedule developed by Leslie N. Smith et al. (2017), the 1cycle policy, and already implemented in fastai. We choose as the maximum learning rate the one derived from the finder above.\n\nlearn.fit_one_cycle(1, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.157843\n-2.199759\n-2.199759\n966.304993\n01:12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith the 1cycle policy we got a good first model, thus we save it and train for a few epochs more.\n\nE=1; model_name = 'sbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/sbm_E1.tar\n\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.263310\n-2.267519\n-2.267519\n1442.309204\n01:09\n\n\n1\n-2.092829\n-2.072918\n-2.072918\n2818.877197\n01:15\n\n\n2\n-1.981965\n-2.144248\n-2.144248\n5740.245605\n01:09\n\n\n3\n-1.960727\n-2.105671\n-2.105671\n8740.739258\n01:10\n\n\n4\n-1.668681\n-1.482724\n-1.482724\n27266.724609\n01:10\n\n\n5\n-2.079590\n-2.127594\n-2.127594\n14647.367188\n01:10\n\n\n6\n-2.141758\n-2.256035\n-2.256035\n14994.700195\n01:11\n\n\n7\n-2.188065\n-2.214240\n-2.214240\n17237.187500\n01:10\n\n\n8\n-2.242931\n-2.223907\n-2.223907\n17943.906250\n01:10\n\n\n9\n-2.258962\n-2.299075\n-2.299075\n19063.156250\n01:14\n\n\n10\n-2.303101\n-2.313661\n-2.313661\n18943.972656\n01:11\n\n\n11\n-2.321828\n-2.326061\n-2.326061\n17432.900391\n01:10\n\n\n12\n-2.323314\n-2.324073\n-2.324073\n16692.931641\n01:12\n\n\n13\n-2.325410\n-2.326961\n-2.326961\n15656.347656\n01:12\n\n\n14\n-2.336070\n-2.330342\n-2.330342\n15198.240234\n01:11\n\n\n15\n-2.342307\n-2.330926\n-2.330926\n15115.720703\n01:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter training, we see a validation loss around -2.33 and two neurons that contribute the most to the \\(D_{KL}\\). We take a checkpoint of the model at this moment.\n\nE=1+16; model_name = 'sbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/sbm_E17.tar\n\n\n\n\nAnnealing \\(\\beta\\)\nNow, we increase \\(\\beta\\) to impose a Gaussian prior into the latent neurons distribution which effectively forces the encoding of the already present information to use the minimal number of neurons while noising out the rest of neurons.\n\nE=17\nmodel_name = 'fbm' + f'_E{E}'\nc_point, model = load_checkpoint(\"./models/\"+model_name,device=DEVICE)\n\nLoading checkpoint: ./models/fbm_E64.tar\non device: cpu\n\n\n\nlearn.loss_func.beta=1e-4; model_args.update(dict(beta=1e-4))\n\n\nlearn.fit_one_cycle(8, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.265089\n-2.256390\n-2.269281\n128.906479\n01:10\n\n\n1\n-2.072519\n-2.171102\n-2.193184\n220.815460\n01:11\n\n\n2\n-2.078890\n-2.010547\n-2.027710\n171.636841\n01:11\n\n\n3\n-2.150817\n-2.082684\n-2.094985\n123.012283\n01:11\n\n\n4\n-2.276386\n-2.275580\n-2.283196\n76.156914\n01:13\n\n\n5\n-2.333585\n-2.269568\n-2.275890\n63.225800\n01:11\n\n\n6\n-2.331838\n-2.324122\n-2.329123\n50.004139\n01:10\n\n\n7\n-2.350273\n-2.325296\n-2.330021\n47.249344\n01:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe save the model after each cycle, just in case all the neurons collapse due to a big \\(\\beta\\).\n\nE=1+16+8; model_name = 'sbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/sbm_E25.tar\n\n\nThen, we increase the \\(\\beta\\) and train again.\n\nlearn.loss_func.beta=1e-3; model_args.update(dict(beta=1e-3))\n\n\nlearn.fit_one_cycle(8, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.281132\n-2.259779\n-2.279295\n19.515345\n01:10\n\n\n1\n-1.824657\n-2.179360\n-2.205580\n26.219692\n01:11\n\n\n2\n-2.211249\n-2.233248\n-2.253192\n19.943052\n01:11\n\n\n3\n-2.257035\n-2.247903\n-2.264651\n16.747833\n01:11\n\n\n4\n-2.289768\n-2.278646\n-2.294806\n16.160137\n01:11\n\n\n5\n-2.303732\n-2.287849\n-2.302872\n15.023915\n01:11\n\n\n6\n-2.342452\n-2.313574\n-2.328554\n14.978462\n01:11\n\n\n7\n-2.326436\n-2.314047\n-2.329060\n15.013249\n01:11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see the \\(D_{KL}\\) of two neurons already dropped two orders of magnitude. We increase \\(\\beta\\) and train more.\n\nE=1+16+8*2; model_name = 'sbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/sbm_E33.tar\n\n\n\nlearn.loss_func.beta=5e-3; model_args.update(dict(beta=5e-3))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.251511\n-2.252467\n-2.306516\n10.809682\n01:10\n\n\n1\n-2.252817\n-2.245228\n-2.293772\n9.708881\n01:11\n\n\n2\n-2.239562\n-2.216622\n-2.256845\n8.044684\n01:12\n\n\n3\n-2.191882\n-1.953922\n-1.985323\n6.280288\n01:11\n\n\n4\n-2.178543\n-2.131708\n-2.163971\n6.452771\n01:11\n\n\n5\n-2.213535\n-2.258947\n-2.288923\n5.995219\n01:11\n\n\n6\n-2.250787\n-2.235217\n-2.263428\n5.642315\n01:12\n\n\n7\n-2.231592\n-2.203765\n-2.230007\n5.248451\n01:11\n\n\n8\n-2.299702\n-2.284002\n-2.309700\n5.139698\n01:11\n\n\n9\n-2.285194\n-2.205304\n-2.230760\n5.091110\n01:13\n\n\n10\n-2.293305\n-2.262668\n-2.287017\n4.869694\n01:12\n\n\n11\n-2.304803\n-2.297028\n-2.321219\n4.838166\n01:11\n\n\n12\n-2.306652\n-2.300437\n-2.324596\n4.831745\n01:11\n\n\n13\n-2.299996\n-2.302048\n-2.326326\n4.855473\n01:11\n\n\n14\n-2.308707\n-2.302276\n-2.326377\n4.820252\n01:12\n\n\n15\n-2.311806\n-2.302298\n-2.326384\n4.817187\n01:12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE=1+16+8*2+16; model_name = 'sbm' + f'_E{E}'\nif not os.path.exists(\"./models/\"+model_name+'.tar'):\n    save_model(\"./models/\"+model_name, model, model_args, ds_args)\n\nSaved at ./models/fbm_E49.tar\n\n\nAfter training, we see a good reconstruction loss around -2.32, while the \\(D_{KL}\\) is on the order of one for two neurons and the rest are two orders of magnitude below. We say that two neurons survive while the rest are noised out. We will see in the analysis tutorial how these two neurons encode the minimal relevant information to generate the trajectories.\n\n\nBigger \\(\\beta\\)\nIf we train with a bigger \\(\\beta\\), eventually one neuron drops, affecting the reconstruction loss that is then worse.\n\nlearn.loss_func.beta=1e-2; model_args.update(dict(beta=1e-2))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.292675\n-2.278427\n-2.320651\n4.222384\n01:09\n\n\n1\n-2.265743\n-2.279128\n-2.320320\n4.119149\n01:10\n\n\n2\n-2.218647\n-2.246289\n-2.288341\n4.205155\n01:13\n\n\n3\n-2.209015\n-2.225596\n-2.265452\n3.985472\n01:12\n\n\n4\n-2.248430\n-2.196464\n-2.238191\n4.172781\n01:12\n\n\n5\n-2.223559\n-2.201737\n-2.243423\n4.168562\n01:12\n\n\n6\n-2.249357\n-2.239655\n-2.279761\n4.010539\n01:14\n\n\n7\n-2.224961\n-2.210147\n-2.251729\n4.158061\n01:13\n\n\n8\n-2.267192\n-2.271090\n-2.312112\n4.102235\n01:14\n\n\n9\n-2.283242\n-2.274777\n-2.314433\n3.965613\n01:13\n\n\n10\n-2.279653\n-2.275052\n-2.314808\n3.975609\n01:13\n\n\n11\n-2.274931\n-2.281827\n-2.321421\n3.959441\n01:12\n\n\n12\n-2.280176\n-2.282479\n-2.321944\n3.946445\n01:12\n\n\n13\n-2.283632\n-2.282778\n-2.322360\n3.958159\n01:12\n\n\n14\n-2.301415\n-2.283230\n-2.322545\n3.931563\n01:11\n\n\n15\n-2.300677\n-2.283238\n-2.322650\n3.941171\n01:12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlearn.loss_func.beta=4e-2; model_args.update(dict(beta=4e-2))\n\n\nlearn.fit_one_cycle(16, lr_max=1e-3,)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nmix_gaussian_loss\nkld\ntime\n\n\n\n\n0\n-2.204268\n-2.183239\n-2.304005\n3.019161\n01:11\n\n\n1\n-2.194592\n-2.175812\n-2.292791\n2.924464\n01:12\n\n\n2\n-2.145626\n-2.180877\n-2.293877\n2.824981\n01:12\n\n\n3\n-2.079138\n-2.172214\n-2.287631\n2.885419\n01:11\n\n\n4\n-2.127781\n-2.103078\n-2.214047\n2.774220\n01:12\n\n\n5\n-2.113369\n-2.036130\n-2.148762\n2.815787\n01:11\n\n\n6\n-2.166729\n-2.182533\n-2.285766\n2.580839\n01:12\n\n\n7\n-2.168032\n-2.187016\n-2.293549\n2.663330\n01:12\n\n\n8\n-2.175102\n-2.190198\n-2.295090\n2.622296\n01:14\n\n\n9\n-2.210599\n-2.195347\n-2.298699\n2.583786\n01:11\n\n\n10\n-2.217565\n-2.165514\n-2.270107\n2.614821\n01:11\n\n\n11\n-2.200825\n-2.198460\n-2.301876\n2.585433\n01:11\n\n\n12\n-2.199532\n-2.199680\n-2.303985\n2.607617\n01:12\n\n\n13\n-2.214851\n-2.200226\n-2.303653\n2.585687\n01:11\n\n\n14\n-2.215913\n-2.200113\n-2.304406\n2.607338\n01:11\n\n\n15\n-2.224487\n-2.200450\n-2.304470\n2.600497\n01:11",
    "crumbs": [
      "Tutorials",
      "Scaled Brownian motion",
      "Model training on SBM"
    ]
  }
]